{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiningho/workspace/datadisk/slicing/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk('result/result')\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['full_text'] = [\n",
    "    '\\n\\n'.join(\n",
    "                [\n",
    "                    \"# Title\\n{title}\\n# Passage\\n{passage}\".format(\n",
    "                        title=title,\n",
    "                        passage=' '.join(sentences)\n",
    "                    ) \n",
    "                    for title, sentences in zip(row[\"context\"][\"title\"], row[\"context\"][\"sentences\"])\n",
    "                ]\n",
    "                + [\n",
    "                    '# Question\\n{question}'.format(question=row[\"question\"])\n",
    "                ]\n",
    "            )\n",
    "    for row in dataset\n",
    "]\n",
    "df['text'] = [\n",
    "    row[\"question\"]\n",
    "    for row in dataset\n",
    "]\n",
    "df['answer'] = [\n",
    "    row['answer']\n",
    "    for row in dataset\n",
    "]\n",
    "df['generated_answer'] = [\n",
    "    row['generated_answer']\n",
    "    for row in dataset\n",
    "]\n",
    "df['level'] = [\n",
    "    row['level']\n",
    "    for row in dataset\n",
    "]\n",
    "df['supporting_facts'] = [\n",
    "    str(row['supporting_facts'])\n",
    "    for row in dataset\n",
    "]\n",
    "df['id'] = [\n",
    "    row['id']\n",
    "    for row in dataset\n",
    "]\n",
    "df.to_csv(\"hotpotQA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compute_f1 import compute_f1\n",
    "from utils.compute_f1 import normalize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "em = []\n",
    "clean_answer = []\n",
    "for i in range(len(dataset)):\n",
    "    # print(dataset[i]['generated_answer'])\n",
    "    # print('####')\n",
    "    idx = dataset[i]['generated_answer'].find('# Answer')\n",
    "    # print(dataset[i]['answer'])\n",
    "    # print('####')\n",
    "    if idx != -1:\n",
    "        clean_answer.append(dataset[i]['generated_answer'][idx + 9:].split('\\n')[0])\n",
    "    else:\n",
    "        clean_answer.append(dataset[i]['generated_answer'].split('\\n')[0])\n",
    "    if clean_answer[-1].lower().find(\"yes\") == 0:\n",
    "        clean_answer[-1] = \"yes\"\n",
    "    elif clean_answer[-1].lower().find(\"no\") == 0:\n",
    "        clean_answer[-1] = \"no\"\n",
    "    # print(clean_answer[i])\n",
    "    # print(\"-------------------------\")\n",
    "    prec, rec, f1 = compute_f1(clean_answer[i], dataset[i]['answer'])\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "    em.append(int(normalize_text(clean_answer[i]) == normalize_text(dataset[i]['answer'])))\n",
    "    \n",
    "    \n",
    "# for i in range(300, 320):\n",
    "#     row = dataset[i]\n",
    "#     # print(row['generated_answer'])\n",
    "#     # print('####')\n",
    "#     print(row['answer'])\n",
    "#     print('####')\n",
    "#     print(row['generated_answer'])\n",
    "#     print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867265567765568\n",
      "0.6302671136653891\n",
      "0.5841558527242717\n",
      "0.44066666666666665\n"
     ]
    }
   ],
   "source": [
    "print(sum(precision) / len(precision))\n",
    "print(sum(recall) / len(recall))\n",
    "print(sum(f1_score) / len(f1_score))\n",
    "\n",
    "print(sum(em) / len(em))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Columns: 157 entries, full_text to label_economy issues\n",
      "dtypes: int64(75), object(82)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from utils.file import read_csv_file, read_txt_file\n",
    "\n",
    "df = read_csv_file(\"result/result1.csv\")\n",
    "#random sample\n",
    "# df = df.sample(n=500)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['multiple languages', 'highly specific topics', 'non-specific topics', 'unspecific topics', 'multiple topics', 'everyday language', 'formal language', 'about movies', 'about books', 'about literature', 'about music', 'about rare topics', 'about common topics', 'with multiple intentions', 'with single intention', 'mention specific people', 'mention specific places', 'mention specific organizations', 'mention specific events', 'mention specific dates', 'mention specific numbers', 'mention specific quantities', 'explicitly biased', 'implicitly biased', 'explicitly subjective', 'implicitly subjective', 'explicitly objective', 'implicitly objective', 'positive sentiment', 'negative sentiment', 'neutral sentiment', 'with multiple sentiments', 'with single sentiment', 'widely known', 'not widely known', 'multiple choices', 'need domain-specific knowledge to understand', 'use ambiguous words', 'need logical reasoning to understand', 'contain homonyms', 'contain synonyms', 'contain antonyms', 'complex sentence structure', 'simple sentence structure', 'answer ranking', 'has location: hospital', 'has location: museum', 'question start with \"who\"', 'question start with \"what\"', 'question start with \"when\"', 'question start with \"where\"', 'question start with \"why\"', 'question start with \"how\"', 'question start with \"which\"', 'question start with \"is\"', 'question start with \"are\"', 'question start with \"do\"', 'question start with \"does\"', 'question start with \"did\"', 'question start with \"can\"', 'question start with \"could\"', 'question start with \"should\"', 'question start with \"would\"', 'question start with \"will\"', 'question start with \"was\"', 'question start with \"were\"', 'question start with \"has\"', 'question start with \"have\"', 'question start with \"had\"', 'question that you can not answer without reading the context', 'question that you can answer without reading the context', 'race issues', 'religion issues', 'politics issues', 'economy issues']\n"
     ]
    }
   ],
   "source": [
    "keywords = read_txt_file(\"data/valid_keywords.txt\")\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5867265567765568\n",
      "0.6302671136653891\n",
      "0.5841558527242717\n",
      "0.44066666666666665\n",
      "keyword: multiple languages\n",
      "true slice: 469 cases\n",
      "prec 0.563\n",
      "rec 0.5925\n",
      "f1 0.5559\n",
      "em 0.3923\n",
      "false slice: 1031 cases\n",
      "prec 0.5975\n",
      "rec 0.6475\n",
      "f1 0.597\n",
      "em 0.4627\n",
      "----\n",
      "keyword: highly specific topics\n",
      "true slice: 48 cases\n",
      "prec 0.6128\n",
      "rec 0.72\n",
      "f1 0.6357\n",
      "em 0.375\n",
      "false slice: 1452 cases\n",
      "prec 0.5859\n",
      "rec 0.6273\n",
      "f1 0.5825\n",
      "em 0.4428\n",
      "----\n",
      "keyword: non-specific topics\n",
      "true slice: 31 cases\n",
      "prec 0.578\n",
      "rec 0.6839\n",
      "f1 0.6028\n",
      "em 0.4516\n",
      "false slice: 1469 cases\n",
      "prec 0.5869\n",
      "rec 0.6291\n",
      "f1 0.5838\n",
      "em 0.4404\n",
      "----\n",
      "keyword: unspecific topics\n",
      "true slice: 49 cases\n",
      "prec 0.2927\n",
      "rec 0.3912\n",
      "f1 0.3137\n",
      "em 0.1224\n",
      "false slice: 1451 cases\n",
      "prec 0.5967\n",
      "rec 0.6383\n",
      "f1 0.5933\n",
      "em 0.4514\n",
      "----\n",
      "keyword: multiple topics\n",
      "true slice: 25 cases\n",
      "prec 0.7133\n",
      "rec 0.678\n",
      "f1 0.6756\n",
      "em 0.56\n",
      "false slice: 1475 cases\n",
      "prec 0.5846\n",
      "rec 0.6295\n",
      "f1 0.5826\n",
      "em 0.4386\n",
      "----\n",
      "keyword: everyday language\n",
      "true slice: 45 cases\n",
      "prec 0.6315\n",
      "rec 0.65\n",
      "f1 0.6294\n",
      "em 0.5111\n",
      "false slice: 1455 cases\n",
      "prec 0.5853\n",
      "rec 0.6297\n",
      "f1 0.5828\n",
      "em 0.4385\n",
      "----\n",
      "keyword: formal language\n",
      "true slice: 2 cases\n",
      "prec 1.0\n",
      "rec 1.0\n",
      "f1 1.0\n",
      "em 1.0\n",
      "false slice: 1498 cases\n",
      "prec 0.5862\n",
      "rec 0.6298\n",
      "f1 0.5836\n",
      "em 0.4399\n",
      "----\n",
      "keyword: about movies\n",
      "true slice: 65 cases\n",
      "prec 0.7226\n",
      "rec 0.7774\n",
      "f1 0.7293\n",
      "em 0.6\n",
      "false slice: 1435 cases\n",
      "prec 0.5806\n",
      "rec 0.6236\n",
      "f1 0.5776\n",
      "em 0.4334\n",
      "----\n",
      "keyword: about books\n",
      "true slice: 126 cases\n",
      "prec 0.6171\n",
      "rec 0.6462\n",
      "f1 0.6046\n",
      "em 0.4127\n",
      "false slice: 1374 cases\n",
      "prec 0.5839\n",
      "rec 0.6288\n",
      "f1 0.5823\n",
      "em 0.4432\n",
      "----\n",
      "keyword: about literature\n",
      "true slice: 124 cases\n",
      "prec 0.5957\n",
      "rec 0.6198\n",
      "f1 0.5776\n",
      "em 0.4194\n",
      "false slice: 1376 cases\n",
      "prec 0.5859\n",
      "rec 0.6312\n",
      "f1 0.5847\n",
      "em 0.4426\n",
      "----\n",
      "keyword: about music\n",
      "true slice: 192 cases\n",
      "prec 0.5899\n",
      "rec 0.6437\n",
      "f1 0.5953\n",
      "em 0.4479\n",
      "false slice: 1308 cases\n",
      "prec 0.5863\n",
      "rec 0.6283\n",
      "f1 0.5825\n",
      "em 0.4396\n",
      "----\n",
      "keyword: about rare topics\n",
      "true slice: 11 cases\n",
      "prec 0.6742\n",
      "rec 0.8636\n",
      "f1 0.703\n",
      "em 0.4545\n",
      "false slice: 1489 cases\n",
      "prec 0.5861\n",
      "rec 0.6285\n",
      "f1 0.5833\n",
      "em 0.4406\n",
      "----\n",
      "keyword: about common topics\n",
      "true slice: 385 cases\n",
      "prec 0.5813\n",
      "rec 0.6123\n",
      "f1 0.5785\n",
      "em 0.4338\n",
      "false slice: 1115 cases\n",
      "prec 0.5886\n",
      "rec 0.6365\n",
      "f1 0.5861\n",
      "em 0.443\n",
      "----\n",
      "keyword: with multiple intentions\n",
      "true slice: 55 cases\n",
      "prec 0.2774\n",
      "rec 0.3662\n",
      "f1 0.2791\n",
      "em 0.1273\n",
      "false slice: 1445 cases\n",
      "prec 0.5985\n",
      "rec 0.6403\n",
      "f1 0.5958\n",
      "em 0.4526\n",
      "----\n",
      "keyword: with single intention\n",
      "true slice: 605 cases\n",
      "prec 0.6038\n",
      "rec 0.6242\n",
      "f1 0.597\n",
      "em 0.4512\n",
      "false slice: 895 cases\n",
      "prec 0.5752\n",
      "rec 0.6343\n",
      "f1 0.5755\n",
      "em 0.4335\n",
      "----\n",
      "keyword: mention specific people\n",
      "true slice: 448 cases\n",
      "prec 0.5782\n",
      "rec 0.6092\n",
      "f1 0.576\n",
      "em 0.4062\n",
      "false slice: 1052 cases\n",
      "prec 0.5904\n",
      "rec 0.6393\n",
      "f1 0.5876\n",
      "em 0.4553\n",
      "----\n",
      "keyword: mention specific places\n",
      "true slice: 582 cases\n",
      "prec 0.5971\n",
      "rec 0.6269\n",
      "f1 0.5875\n",
      "em 0.4313\n",
      "false slice: 918 cases\n",
      "prec 0.5801\n",
      "rec 0.6324\n",
      "f1 0.582\n",
      "em 0.4466\n",
      "----\n",
      "keyword: mention specific organizations\n",
      "true slice: 332 cases\n",
      "prec 0.6231\n",
      "rec 0.6511\n",
      "f1 0.6227\n",
      "em 0.4669\n",
      "false slice: 1168 cases\n",
      "prec 0.5764\n",
      "rec 0.6243\n",
      "f1 0.5732\n",
      "em 0.4332\n",
      "----\n",
      "keyword: mention specific events\n",
      "true slice: 159 cases\n",
      "prec 0.6016\n",
      "rec 0.6277\n",
      "f1 0.5945\n",
      "em 0.4465\n",
      "false slice: 1341 cases\n",
      "prec 0.585\n",
      "rec 0.6306\n",
      "f1 0.5829\n",
      "em 0.44\n",
      "----\n",
      "keyword: mention specific dates\n",
      "true slice: 252 cases\n",
      "prec 0.6541\n",
      "rec 0.6549\n",
      "f1 0.628\n",
      "em 0.4841\n",
      "false slice: 1248 cases\n",
      "prec 0.5731\n",
      "rec 0.6253\n",
      "f1 0.5753\n",
      "em 0.4319\n",
      "----\n",
      "keyword: mention specific numbers\n",
      "true slice: 9 cases\n",
      "prec 0.7407\n",
      "rec 0.7407\n",
      "f1 0.7407\n",
      "em 0.6667\n",
      "false slice: 1491 cases\n",
      "prec 0.5858\n",
      "rec 0.6296\n",
      "f1 0.5832\n",
      "em 0.4393\n",
      "----\n",
      "keyword: mention specific quantities\n",
      "true slice: 0 cases\n",
      "prec nan\n",
      "rec nan\n",
      "f1 nan\n",
      "em nan\n",
      "false slice: 1500 cases\n",
      "prec 0.5867\n",
      "rec 0.6303\n",
      "f1 0.5842\n",
      "em 0.4407\n",
      "----\n",
      "keyword: explicitly biased\n",
      "true slice: 0 cases\n",
      "prec nan\n",
      "rec nan\n",
      "f1 nan\n",
      "em nan\n",
      "false slice: 1500 cases\n",
      "prec 0.5867\n",
      "rec 0.6303\n",
      "f1 0.5842\n",
      "em 0.4407\n",
      "----\n",
      "keyword: implicitly biased\n",
      "true slice: 158 cases\n",
      "prec 0.5068\n",
      "rec 0.5527\n",
      "f1 0.5076\n",
      "em 0.3418\n",
      "false slice: 1342 cases\n",
      "prec 0.5961\n",
      "rec 0.6394\n",
      "f1 0.5932\n",
      "em 0.4523\n",
      "----\n",
      "keyword: explicitly subjective\n",
      "true slice: 2 cases\n",
      "prec 0.5\n",
      "rec 1.0\n",
      "f1 0.6667\n",
      "em 0.0\n",
      "false slice: 1498 cases\n",
      "prec 0.5868\n",
      "rec 0.6298\n",
      "f1 0.584\n",
      "em 0.4413\n",
      "----\n",
      "keyword: implicitly subjective\n",
      "true slice: 108 cases\n",
      "prec 0.6146\n",
      "rec 0.6655\n",
      "f1 0.6174\n",
      "em 0.4537\n",
      "false slice: 1392 cases\n",
      "prec 0.5846\n",
      "rec 0.6275\n",
      "f1 0.5816\n",
      "em 0.4397\n",
      "----\n",
      "keyword: explicitly objective\n",
      "true slice: 0 cases\n",
      "prec nan\n",
      "rec nan\n",
      "f1 nan\n",
      "em nan\n",
      "false slice: 1500 cases\n",
      "prec 0.5867\n",
      "rec 0.6303\n",
      "f1 0.5842\n",
      "em 0.4407\n",
      "----\n",
      "keyword: implicitly objective\n",
      "true slice: 0 cases\n",
      "prec nan\n",
      "rec nan\n",
      "f1 nan\n",
      "em nan\n",
      "false slice: 1500 cases\n",
      "prec 0.5867\n",
      "rec 0.6303\n",
      "f1 0.5842\n",
      "em 0.4407\n",
      "----\n",
      "keyword: positive sentiment\n",
      "true slice: 227 cases\n",
      "prec 0.6348\n",
      "rec 0.6762\n",
      "f1 0.6367\n",
      "em 0.4714\n",
      "false slice: 1273 cases\n",
      "prec 0.5782\n",
      "rec 0.6221\n",
      "f1 0.5748\n",
      "em 0.4352\n",
      "----\n",
      "keyword: negative sentiment\n",
      "true slice: 7 cases\n",
      "prec 0.6429\n",
      "rec 0.7143\n",
      "f1 0.6667\n",
      "em 0.5714\n",
      "false slice: 1493 cases\n",
      "prec 0.5865\n",
      "rec 0.6299\n",
      "f1 0.5838\n",
      "em 0.4401\n",
      "----\n",
      "keyword: neutral sentiment\n",
      "true slice: 75 cases\n",
      "prec 0.6969\n",
      "rec 0.7067\n",
      "f1 0.6894\n",
      "em 0.5733\n",
      "false slice: 1425 cases\n",
      "prec 0.5809\n",
      "rec 0.6262\n",
      "f1 0.5786\n",
      "em 0.4337\n",
      "----\n",
      "keyword: with multiple sentiments\n",
      "true slice: 112 cases\n",
      "prec 0.5656\n",
      "rec 0.6382\n",
      "f1 0.5792\n",
      "em 0.4018\n",
      "false slice: 1388 cases\n",
      "prec 0.5884\n",
      "rec 0.6296\n",
      "f1 0.5846\n",
      "em 0.4438\n",
      "----\n",
      "keyword: with single sentiment\n",
      "true slice: 388 cases\n",
      "prec 0.6404\n",
      "rec 0.6558\n",
      "f1 0.6308\n",
      "em 0.4923\n",
      "false slice: 1112 cases\n",
      "prec 0.568\n",
      "rec 0.6213\n",
      "f1 0.5679\n",
      "em 0.4227\n",
      "----\n",
      "keyword: widely known\n",
      "true slice: 16 cases\n",
      "prec 0.7979\n",
      "rec 0.85\n",
      "f1 0.8167\n",
      "em 0.6875\n",
      "false slice: 1484 cases\n",
      "prec 0.5844\n",
      "rec 0.6279\n",
      "f1 0.5816\n",
      "em 0.438\n",
      "----\n",
      "keyword: not widely known\n",
      "true slice: 0 cases\n",
      "prec nan\n",
      "rec nan\n",
      "f1 nan\n",
      "em nan\n",
      "false slice: 1500 cases\n",
      "prec 0.5867\n",
      "rec 0.6303\n",
      "f1 0.5842\n",
      "em 0.4407\n",
      "----\n",
      "keyword: multiple choices\n",
      "true slice: 55 cases\n",
      "prec 0.3652\n",
      "rec 0.4658\n",
      "f1 0.3773\n",
      "em 0.2\n",
      "false slice: 1445 cases\n",
      "prec 0.5952\n",
      "rec 0.6365\n",
      "f1 0.592\n",
      "em 0.4498\n",
      "----\n",
      "keyword: need domain-specific knowledge to understand\n",
      "true slice: 0 cases\n",
      "prec nan\n",
      "rec nan\n",
      "f1 nan\n",
      "em nan\n",
      "false slice: 1500 cases\n",
      "prec 0.5867\n",
      "rec 0.6303\n",
      "f1 0.5842\n",
      "em 0.4407\n",
      "----\n",
      "keyword: use ambiguous words\n",
      "true slice: 175 cases\n",
      "prec 0.5657\n",
      "rec 0.5958\n",
      "f1 0.5631\n",
      "em 0.4229\n",
      "false slice: 1325 cases\n",
      "prec 0.5895\n",
      "rec 0.6348\n",
      "f1 0.5869\n",
      "em 0.443\n",
      "----\n",
      "keyword: need logical reasoning to understand\n",
      "true slice: 277 cases\n",
      "prec 0.5372\n",
      "rec 0.5962\n",
      "f1 0.5412\n",
      "em 0.3899\n",
      "false slice: 1223 cases\n",
      "prec 0.5979\n",
      "rec 0.638\n",
      "f1 0.5939\n",
      "em 0.4522\n",
      "----\n",
      "keyword: contain homonyms\n",
      "true slice: 1069 cases\n",
      "prec 0.5823\n",
      "rec 0.62\n",
      "f1 0.5787\n",
      "em 0.4284\n",
      "false slice: 431 cases\n",
      "prec 0.5977\n",
      "rec 0.6558\n",
      "f1 0.5977\n",
      "em 0.471\n",
      "----\n",
      "keyword: contain synonyms\n",
      "true slice: 1383 cases\n",
      "prec 0.5804\n",
      "rec 0.6227\n",
      "f1 0.5781\n",
      "em 0.4338\n",
      "false slice: 117 cases\n",
      "prec 0.661\n",
      "rec 0.7194\n",
      "f1 0.656\n",
      "em 0.5214\n",
      "----\n",
      "keyword: contain antonyms\n",
      "true slice: 1451 cases\n",
      "prec 0.5799\n",
      "rec 0.6236\n",
      "f1 0.5774\n",
      "em 0.4328\n",
      "false slice: 49 cases\n",
      "prec 0.7878\n",
      "rec 0.8272\n",
      "f1 0.783\n",
      "em 0.6735\n",
      "----\n",
      "keyword: complex sentence structure\n",
      "true slice: 1 cases\n",
      "prec 0.5\n",
      "rec 1.0\n",
      "f1 0.6667\n",
      "em 0.0\n",
      "false slice: 1499 cases\n",
      "prec 0.5868\n",
      "rec 0.63\n",
      "f1 0.5841\n",
      "em 0.441\n",
      "----\n",
      "keyword: simple sentence structure\n",
      "true slice: 79 cases\n",
      "prec 0.6595\n",
      "rec 0.681\n",
      "f1 0.6546\n",
      "em 0.4937\n",
      "false slice: 1421 cases\n",
      "prec 0.5827\n",
      "rec 0.6274\n",
      "f1 0.5802\n",
      "em 0.4377\n",
      "----\n",
      "keyword: answer ranking\n",
      "true slice: 12 cases\n",
      "prec 0.3194\n",
      "rec 0.4306\n",
      "f1 0.3565\n",
      "em 0.1667\n",
      "false slice: 1488 cases\n",
      "prec 0.5889\n",
      "rec 0.6319\n",
      "f1 0.586\n",
      "em 0.4429\n",
      "----\n",
      "keyword: has location: hospital\n",
      "true slice: 10 cases\n",
      "prec 0.6444\n",
      "rec 0.75\n",
      "f1 0.6615\n",
      "em 0.4\n",
      "false slice: 1490 cases\n",
      "prec 0.5863\n",
      "rec 0.6295\n",
      "f1 0.5836\n",
      "em 0.4409\n",
      "----\n",
      "keyword: has location: museum\n",
      "true slice: 2 cases\n",
      "prec 1.0\n",
      "rec 1.0\n",
      "f1 1.0\n",
      "em 1.0\n",
      "false slice: 1498 cases\n",
      "prec 0.5862\n",
      "rec 0.6298\n",
      "f1 0.5836\n",
      "em 0.4399\n",
      "----\n",
      "keyword: question start with \"who\"\n",
      "true slice: 525 cases\n",
      "prec 0.5851\n",
      "rec 0.6129\n",
      "f1 0.5765\n",
      "em 0.3848\n",
      "false slice: 975 cases\n",
      "prec 0.5876\n",
      "rec 0.6396\n",
      "f1 0.5883\n",
      "em 0.4708\n",
      "----\n",
      "keyword: question start with \"what\"\n",
      "true slice: 480 cases\n",
      "prec 0.5676\n",
      "rec 0.617\n",
      "f1 0.5737\n",
      "em 0.4354\n",
      "false slice: 1020 cases\n",
      "prec 0.5957\n",
      "rec 0.6365\n",
      "f1 0.5891\n",
      "em 0.4431\n",
      "----\n",
      "keyword: question start with \"when\"\n",
      "true slice: 249 cases\n",
      "prec 0.6207\n",
      "rec 0.5922\n",
      "f1 0.5846\n",
      "em 0.4378\n",
      "false slice: 1251 cases\n",
      "prec 0.58\n",
      "rec 0.6378\n",
      "f1 0.5841\n",
      "em 0.4412\n",
      "----\n",
      "keyword: question start with \"where\"\n",
      "true slice: 255 cases\n",
      "prec 0.6343\n",
      "rec 0.6433\n",
      "f1 0.619\n",
      "em 0.4941\n",
      "false slice: 1245 cases\n",
      "prec 0.577\n",
      "rec 0.6276\n",
      "f1 0.577\n",
      "em 0.4297\n",
      "----\n",
      "keyword: question start with \"why\"\n",
      "true slice: 312 cases\n",
      "prec 0.5411\n",
      "rec 0.5718\n",
      "f1 0.5359\n",
      "em 0.3686\n",
      "false slice: 1188 cases\n",
      "prec 0.5987\n",
      "rec 0.6456\n",
      "f1 0.5968\n",
      "em 0.4596\n",
      "----\n",
      "keyword: question start with \"how\"\n",
      "true slice: 914 cases\n",
      "prec 0.5655\n",
      "rec 0.6063\n",
      "f1 0.5612\n",
      "em 0.4147\n",
      "false slice: 586 cases\n",
      "prec 0.6198\n",
      "rec 0.6676\n",
      "f1 0.6199\n",
      "em 0.4812\n",
      "----\n",
      "keyword: question start with \"which\"\n",
      "true slice: 860 cases\n",
      "prec 0.5682\n",
      "rec 0.6315\n",
      "f1 0.5694\n",
      "em 0.4023\n",
      "false slice: 640 cases\n",
      "prec 0.6116\n",
      "rec 0.6287\n",
      "f1 0.6039\n",
      "em 0.4922\n",
      "----\n",
      "keyword: question start with \"is\"\n",
      "true slice: 724 cases\n",
      "prec 0.5693\n",
      "rec 0.6226\n",
      "f1 0.5679\n",
      "em 0.4061\n",
      "false slice: 776 cases\n",
      "prec 0.603\n",
      "rec 0.6374\n",
      "f1 0.5993\n",
      "em 0.4729\n",
      "----\n",
      "keyword: question start with \"are\"\n",
      "true slice: 291 cases\n",
      "prec 0.6053\n",
      "rec 0.6357\n",
      "f1 0.6072\n",
      "em 0.5086\n",
      "false slice: 1209 cases\n",
      "prec 0.5822\n",
      "rec 0.629\n",
      "f1 0.5786\n",
      "em 0.4243\n",
      "----\n",
      "keyword: question start with \"do\"\n",
      "true slice: 340 cases\n",
      "prec 0.4766\n",
      "rec 0.5303\n",
      "f1 0.4831\n",
      "em 0.3265\n",
      "false slice: 1160 cases\n",
      "prec 0.619\n",
      "rec 0.6596\n",
      "f1 0.6138\n",
      "em 0.4741\n",
      "----\n",
      "keyword: question start with \"does\"\n",
      "true slice: 553 cases\n",
      "prec 0.5453\n",
      "rec 0.5923\n",
      "f1 0.5447\n",
      "em 0.3852\n",
      "false slice: 947 cases\n",
      "prec 0.6109\n",
      "rec 0.6524\n",
      "f1 0.6072\n",
      "em 0.4731\n",
      "----\n",
      "keyword: question start with \"did\"\n",
      "true slice: 241 cases\n",
      "prec 0.5811\n",
      "rec 0.6215\n",
      "f1 0.581\n",
      "em 0.4398\n",
      "false slice: 1259 cases\n",
      "prec 0.5878\n",
      "rec 0.6319\n",
      "f1 0.5848\n",
      "em 0.4408\n",
      "----\n",
      "keyword: question start with \"can\"\n",
      "true slice: 156 cases\n",
      "prec 0.4605\n",
      "rec 0.5213\n",
      "f1 0.4678\n",
      "em 0.2821\n",
      "false slice: 1344 cases\n",
      "prec 0.6014\n",
      "rec 0.6429\n",
      "f1 0.5977\n",
      "em 0.4591\n",
      "----\n",
      "keyword: question start with \"could\"\n",
      "true slice: 49 cases\n",
      "prec 0.4677\n",
      "rec 0.5301\n",
      "f1 0.4794\n",
      "em 0.2857\n",
      "false slice: 1451 cases\n",
      "prec 0.5907\n",
      "rec 0.6336\n",
      "f1 0.5877\n",
      "em 0.4459\n",
      "----\n",
      "keyword: question start with \"should\"\n",
      "true slice: 2 cases\n",
      "prec 0.375\n",
      "rec 0.5\n",
      "f1 0.4167\n",
      "em 0.0\n",
      "false slice: 1498 cases\n",
      "prec 0.587\n",
      "rec 0.6304\n",
      "f1 0.5844\n",
      "em 0.4413\n",
      "----\n",
      "keyword: question start with \"would\"\n",
      "true slice: 9 cases\n",
      "prec 0.5\n",
      "rec 0.7778\n",
      "f1 0.5778\n",
      "em 0.2222\n",
      "false slice: 1491 cases\n",
      "prec 0.5873\n",
      "rec 0.6294\n",
      "f1 0.5842\n",
      "em 0.442\n",
      "----\n",
      "keyword: question start with \"will\"\n",
      "true slice: 62 cases\n",
      "prec 0.6331\n",
      "rec 0.678\n",
      "f1 0.6294\n",
      "em 0.4516\n",
      "false slice: 1438 cases\n",
      "prec 0.5847\n",
      "rec 0.6282\n",
      "f1 0.5822\n",
      "em 0.4402\n",
      "----\n",
      "keyword: question start with \"was\"\n",
      "true slice: 1017 cases\n",
      "prec 0.5727\n",
      "rec 0.6004\n",
      "f1 0.5664\n",
      "em 0.414\n",
      "false slice: 483 cases\n",
      "prec 0.6162\n",
      "rec 0.6932\n",
      "f1 0.6216\n",
      "em 0.4969\n",
      "----\n",
      "keyword: question start with \"were\"\n",
      "true slice: 34 cases\n",
      "prec 0.3775\n",
      "rec 0.4363\n",
      "f1 0.3845\n",
      "em 0.1765\n",
      "false slice: 1466 cases\n",
      "prec 0.5916\n",
      "rec 0.6348\n",
      "f1 0.5888\n",
      "em 0.4468\n",
      "----\n",
      "keyword: question start with \"has\"\n",
      "true slice: 1261 cases\n",
      "prec 0.5801\n",
      "rec 0.626\n",
      "f1 0.5788\n",
      "em 0.437\n",
      "false slice: 239 cases\n",
      "prec 0.6219\n",
      "rec 0.6528\n",
      "f1 0.6125\n",
      "em 0.4603\n",
      "----\n",
      "keyword: question start with \"have\"\n",
      "true slice: 1313 cases\n",
      "prec 0.576\n",
      "rec 0.623\n",
      "f1 0.5751\n",
      "em 0.4311\n",
      "false slice: 187 cases\n",
      "prec 0.6619\n",
      "rec 0.6816\n",
      "f1 0.6478\n",
      "em 0.508\n",
      "----\n",
      "keyword: question start with \"had\"\n",
      "true slice: 399 cases\n",
      "prec 0.5505\n",
      "rec 0.5897\n",
      "f1 0.5518\n",
      "em 0.406\n",
      "false slice: 1101 cases\n",
      "prec 0.5998\n",
      "rec 0.645\n",
      "f1 0.5959\n",
      "em 0.4532\n",
      "----\n",
      "keyword: question that you can not answer without reading the context\n",
      "true slice: 383 cases\n",
      "prec 0.5961\n",
      "rec 0.6173\n",
      "f1 0.5862\n",
      "em 0.4674\n",
      "false slice: 1117 cases\n",
      "prec 0.5835\n",
      "rec 0.6347\n",
      "f1 0.5835\n",
      "em 0.4315\n",
      "----\n",
      "keyword: question that you can answer without reading the context\n",
      "true slice: 2 cases\n",
      "prec 0.6667\n",
      "rec 1.0\n",
      "f1 0.75\n",
      "em 0.5\n",
      "false slice: 1498 cases\n",
      "prec 0.5866\n",
      "rec 0.6298\n",
      "f1 0.5839\n",
      "em 0.4406\n",
      "----\n",
      "keyword: race issues\n",
      "true slice: 1 cases\n",
      "prec 1.0\n",
      "rec 1.0\n",
      "f1 1.0\n",
      "em 1.0\n",
      "false slice: 1499 cases\n",
      "prec 0.5865\n",
      "rec 0.63\n",
      "f1 0.5839\n",
      "em 0.4403\n",
      "----\n",
      "keyword: religion issues\n",
      "true slice: 95 cases\n",
      "prec 0.5794\n",
      "rec 0.6288\n",
      "f1 0.5814\n",
      "em 0.4\n",
      "false slice: 1405 cases\n",
      "prec 0.5872\n",
      "rec 0.6304\n",
      "f1 0.5843\n",
      "em 0.4434\n",
      "----\n",
      "keyword: politics issues\n",
      "true slice: 12 cases\n",
      "prec 0.7333\n",
      "rec 0.6528\n",
      "f1 0.6713\n",
      "em 0.5\n",
      "false slice: 1488 cases\n",
      "prec 0.5855\n",
      "rec 0.6301\n",
      "f1 0.5835\n",
      "em 0.4402\n",
      "----\n",
      "keyword: economy issues\n",
      "true slice: 1 cases\n",
      "prec 0.5\n",
      "rec 1.0\n",
      "f1 0.6667\n",
      "em 0.0\n",
      "false slice: 1499 cases\n",
      "prec 0.5868\n",
      "rec 0.63\n",
      "f1 0.5841\n",
      "em 0.441\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "add_col = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "em = []\n",
    "clean = []\n",
    "for index, row in df.iterrows():\n",
    "    clean_answer = row['generated_answer']\n",
    "    idx = clean_answer.find('# Answer')\n",
    "    if idx != -1:\n",
    "        clean_answer = clean_answer[idx + 9:].split('\\n')[0]\n",
    "    else:\n",
    "        clean_answer = clean_answer.split('\\n')[0]\n",
    "    if clean_answer.lower().find(\"yes\") == 0:\n",
    "        clean_answer = \"yes\"\n",
    "    elif clean_answer.lower().find(\"no\") == 0:\n",
    "        clean_answer = \"no\"\n",
    "    prec, rec, f1 = compute_f1(clean_answer, row['answer'])\n",
    "    add_col.append(clean_answer)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "    em.append(int(normalize_text(clean_answer) == normalize_text(row['answer'])))\n",
    "    clean.append(clean_answer)\n",
    "df['generated_answer'] = clean\n",
    "    # print(row['label_{keyword}'.format(keyword='ambigious question_meta')])\n",
    "print(sum(precision) / len(precision))\n",
    "print(sum(recall) / len(recall))\n",
    "print(sum(f1_score) / len(f1_score))\n",
    "print(sum(em) / len(em))\n",
    "df[\"clean_answer\"] = add_col\n",
    "df[\"precision\"] = precision\n",
    "df[\"recall\"] = recall\n",
    "df[\"f1\"] = f1_score\n",
    "df[\"em\"] = em\n",
    "# import random\n",
    "# df['random'] = [random.randint(0, 1) for i in range(len(df))]\n",
    "for keyword in keywords:\n",
    "    true_df = df[df['label_{keyword}'.format(keyword=keyword)] == 1]\n",
    "    false_df = df[df['label_{keyword}'.format(keyword=keyword)] != 1]\n",
    "    print(\"keyword:\", keyword)\n",
    "    print(\"true slice:\", len(true_df), \"cases\")\n",
    "    print(\"prec\", round(true_df[\"precision\"].mean(), 4))\n",
    "    print(\"rec\", round(true_df[\"recall\"].mean(), 4))\n",
    "    print(\"f1\", round(true_df[\"f1\"].mean(), 4))\n",
    "    print(\"em\", round(true_df[\"em\"].mean(), 4))\n",
    "    print(\"false slice:\", len(false_df), \"cases\")\n",
    "    print(\"prec\", round(false_df[\"precision\"].mean(), 4))\n",
    "    print(\"rec\", round(false_df[\"recall\"].mean(), 4))\n",
    "    print(\"f1\", round(false_df[\"f1\"].mean(), 4))\n",
    "    print(\"em\", round(false_df[\"em\"].mean(), 4))\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "'non-specific topics',\n",
    "'everyday language',\n",
    "'formal language',\n",
    "'about rare topics',\n",
    "'mention specific quantities',\n",
    "'explicitly biased',\n",
    "'explicitly subjective',\n",
    "'implicitly subjective',\n",
    "'explicitly objective',\n",
    "'implicitly objective',\n",
    "'positive sentiment',\n",
    "'negative sentiment',\n",
    "'neutral sentiment',\n",
    "'not widely known',\n",
    "'need domain-specific knowledge to understand',\n",
    "'contain homonyms',\n",
    "'contain synonyms',\n",
    "'contain antonyms',\n",
    "'complex sentence structure',\n",
    "'question start with \"who\"',\n",
    "'question start with \"what\"',\n",
    "'question start with \"when\"',\n",
    "'question start with \"where\"',\n",
    "'question start with \"why\"',\n",
    "'question start with \"how\"',\n",
    "'question start with \"which\"',\n",
    "'question start with \"is\"',\n",
    "'question start with \"are\"',\n",
    "'question start with \"do\"',\n",
    "'question start with \"does\"',\n",
    "'question start with \"has\"',\n",
    "'question start with \"did\"',\n",
    "'question start with \"have\"',\n",
    "'race issues',\n",
    "'question start with \"had\"',\n",
    "'question start with \"can\"',\n",
    "'question start with \"could\"',\n",
    "'question start with \"should\"',\n",
    "'question start with \"were\"',\n",
    "'question start with \"would\"',\n",
    "'question start with \"was\"',\n",
    "'question start with \"will\"',\n",
    "]\n",
    "df = df.drop(labels=['label_{key}_meta'.format(key=key) for key in keywords], axis=1)\n",
    "df = df.drop(labels=['label_{key}'.format(key=key) for key in keywords], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.columns.tolist())\n",
    "# print(df.info())\n",
    "# column = df.columns.tolist()\n",
    "# for key in column:\n",
    "#     if key.find(\"slice:\") == 0:\n",
    "#         df = df.rename(columns={key: 'slicing result for ' + key})\n",
    "df.to_csv('final_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unspecific topics\n",
      "True:\n",
      "question: Grzegorz Piramowicz was a member of an Education group considered what?\n",
      "answer: it is considered the first Ministry of Education in European history\n",
      "generated_answer: Polish Enlightenment commission\n",
      "label reason: My answer is yes. The text does not provide any specific details or context that would limit its applicability to a specific situation. The language used is general and could be applied to a wide range of situations where a group of people are considering something. For example, the text could be applied to a group of students discussing a school project, a group of colleagues brainstorming ideas for a work project, or a group of friends deciding on a vacation destination.\n",
      "------------------------------------\n",
      "question: How are Fred Guiol and Stuart Paton alike?\n",
      "answer: film director and screenwriter.\n",
      "generated_answer:  Both directed Laurel and Hardy films.\n",
      "label reason: My answer is yes. The text provides general information about Fred Guiol and Stuart Paton, which can be applied to unspecific situations. The text does not provide any specific details or context that would limit its applicability to a particular situation. Therefore, it can be applied to unspecific situations where the characteristics mentioned in the text are relevant.\n",
      "------------------------------------\n",
      "question: What do  Jacques Tourneur and Djibril Diop Mambéty have in common?\n",
      "answer: director\n",
      "generated_answer: Both directed film noir classics.\n",
      "label reason: My answer is yes. The text provides general information about Jacques Tourneur and Djibril Diop Mambéty, two filmmakers who are mentioned as examples of African filmmakers who have contributed to the development of African cinema. The text does not provide specific details about their work or personal lives, but rather provides a brief overview of their contributions to the film industry. Therefore, the text can be applied to unspecific situations where a general overview of African filmmakers is needed.\n",
      "------------------------------------\n",
      "question: Who is an award-winning Austrian artist, filmmaker, writer, actor, curator, theatre director and lecturer, Johannes Grenzfurthner or Jaap Speyer?\n",
      "answer: Johannes Grenzfurthner\n",
      "generated_answer: Johannes Grenzfurthner\n",
      "label reason: My answer is yes. The text does not provide any specific information about the person being referred to, and instead uses general terms that could apply to anyone. For example, the text mentions that the person is an \"award-winning\" artist, which could refer to any artist who has received recognition for their work, regardless of their name or background. Similarly, the text mentions that the person is a \"filmmaker,\" \"writer,\" \"actor,\" \"curator,\" \"theatre director,\" and \"lecturer,\" which are all professions that could be held by anyone with those skills and interests. Therefore, the text can be applied to unspecific situations and could refer to any person who fits the described categories.\n",
      "------------------------------------\n",
      "question: Adorable and Goon Moon are both what?\n",
      "answer: rock band\n",
      "generated_answer: Both are bands.\n",
      "label reason: My answer is yes. The text describes two entities, Adorable and Goon Moon, which are both nouns. The use of the word \"are\" in the text indicates that these entities are distinct and separate, which suggests that they can be applied to unspecific situations. For example, one could imagine Adorable and Goon Moon being used to describe two different people or objects in different contexts.\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "False:\n",
      "question: Are Gaoyou and Arxan both located in China?\n",
      "answer: no\n",
      "generated_answer: yes\n",
      "label reason: My answer is no. The text specifically states that Gaoyou and Arxan are both located in China, which limits its applicability to specific situations within China.\n",
      "------------------------------------\n",
      "question: What United States Army post, based in  the Nome Census Area of Alaska, is named for an officer who served in the American Civil War? \n",
      "answer: Fort Davis\n",
      "generated_answer: Jefferson Davis\n",
      "label reason: My answer is no. The text specifically refers to an officer who served in the American Civil War, which was a historical event that took place in the 19th century. It is unlikely that an officer from that time period would be named for a post in the 21st century.\n",
      "------------------------------------\n",
      "question: What was the 2001 film that won Russell Crowe multiple awards for his portrayal of the mathematician John Forbes Nash Jr?\n",
      "answer: A Beautiful Mind\n",
      "generated_answer: A Beautiful Mind\n",
      "label reason: My answer is no. The text specifically refers to the 2001 film \"A Beautiful Mind\" in which Russell Crowe portrayed the mathematician John Forbes Nash Jr. The text does not provide any information that could be applied to unspecific situations.\n",
      "------------------------------------\n",
      "question: Words of Radiance was a part of which series written by Brandon Sanderson?\n",
      "answer: The Stormlight Archive\n",
      "generated_answer: The Stormlight Archive series\n",
      "label reason: My answer is no. The text \"Words of Radiance\" is specifically mentioned as being part of the Stormlight Archive series written by Brandon Sanderson. It does not provide any generalizable insights that can be applied to unspecific situations.\n",
      "------------------------------------\n",
      "question:  What home stadium that Caio Henrique Oliveira Silva plays as an attacking midfielder?\n",
      "answer: Cerro del Espino Stadium\n",
      "generated_answer: Cerro del Espino Stadium.\n",
      "label reason: My answer is no. The text specifically refers to Caio Henrique Oliveira Silva, an attacking midfielder, and his home stadium. It does not provide any general information that could be applied to unspecific situations.\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_keywords = [\n",
    "    # \"question that need commen sense to answer\",\n",
    "    # \"multiple possible interpretations\",\n",
    "    'unspecific topics'\n",
    "]\n",
    "\n",
    "for keyword in print_keywords:\n",
    "    true_df = df[df['label_{keyword}'.format(keyword=keyword)] == 1]\n",
    "    false_df = df[df['label_{keyword}'.format(keyword=keyword)] != 1]\n",
    "    print(keyword)\n",
    "    random_true_df = true_df.sample(n=5)\n",
    "    random_false_df = false_df.sample(n=5)\n",
    "    print(\"True:\")\n",
    "    for index, row in random_true_df.iterrows():\n",
    "        print(\"question:\", row['text'])\n",
    "        print(\"answer:\", row['answer'])\n",
    "        print(\"generated_answer:\", row['clean_answer'])\n",
    "        print(\"label reason:\", row['label_{keyword}_meta'.format(keyword=keyword)])\n",
    "        print(\"------------------------------------\")\n",
    "    print(\"\\n\\nFalse:\")\n",
    "    for index, row in random_false_df.iterrows():\n",
    "        print(\"question:\", row['text'])\n",
    "        print(\"answer:\", row['answer'])\n",
    "        print(\"generated_answer:\", row['clean_answer'])\n",
    "        print(\"label reason:\", row['label_{keyword}_meta'.format(keyword=keyword)])\n",
    "        print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
