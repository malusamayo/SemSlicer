{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 24 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   text          500 non-null    object \n",
      " 1   label         500 non-null    int64  \n",
      " 2   result        500 non-null    float64\n",
      " 3   prompt0_meta  500 non-null    object \n",
      " 4   prompt0       500 non-null    int64  \n",
      " 5   prompt1_meta  500 non-null    object \n",
      " 6   prompt1       500 non-null    int64  \n",
      " 7   prompt2_meta  500 non-null    object \n",
      " 8   prompt2       500 non-null    int64  \n",
      " 9   prompt3_meta  500 non-null    object \n",
      " 10  prompt3       500 non-null    int64  \n",
      " 11  prompt4_meta  500 non-null    object \n",
      " 12  prompt4       500 non-null    int64  \n",
      " 13  prompt5_meta  500 non-null    object \n",
      " 14  prompt5       500 non-null    int64  \n",
      " 15  prompt6_meta  500 non-null    object \n",
      " 16  prompt6       500 non-null    int64  \n",
      " 17  prompt7_meta  500 non-null    object \n",
      " 18  prompt7       500 non-null    int64  \n",
      " 19  prompt8_meta  500 non-null    object \n",
      " 20  prompt8       500 non-null    int64  \n",
      " 21  prompt9_meta  500 non-null    object \n",
      " 22  prompt9       500 non-null    int64  \n",
      " 23  hypothesis    500 non-null    int64  \n",
      "dtypes: float64(1), int64(12), object(11)\n",
      "memory usage: 93.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = read_csv_file('result.csv')\n",
    "print(df.info())\n",
    "# df['result'] = 0\n",
    "# for i in range(5):\n",
    "#     df['result'] += df['prompt{}'.format(i)]\n",
    "# df['result'] /= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.5\n",
      "precision = 0.6384\n",
      "recall = 0.7588\n",
      "accuracy = 0.694\n",
      "0\n",
      "precision = 0.7277\n",
      "recall = 0.6798\n",
      "accuracy = 0.738\n",
      "1\n",
      "precision = 0.6694\n",
      "recall = 0.7193\n",
      "accuracy = 0.71\n",
      "2\n",
      "precision = 0.7198\n",
      "recall = 0.5746\n",
      "accuracy = 0.704\n",
      "3\n",
      "precision = 0.6175\n",
      "recall = 0.7719\n",
      "accuracy = 0.678\n",
      "4\n",
      "precision = 0.5452\n",
      "recall = 0.7412\n",
      "accuracy = 0.6\n",
      "5\n",
      "precision = 0.7064\n",
      "recall = 0.7281\n",
      "accuracy = 0.738\n",
      "6\n",
      "precision = 0.6258\n",
      "recall = 0.8289\n",
      "accuracy = 0.696\n",
      "7\n",
      "precision = 0.6148\n",
      "recall = 0.7281\n",
      "accuracy = 0.668\n",
      "8\n",
      "precision = 0.5116\n",
      "recall = 0.7719\n",
      "accuracy = 0.56\n",
      "9\n",
      "precision = 0.5424\n",
      "recall = 0.8421\n",
      "accuracy = 0.604\n",
      "max real positive accuracy: 0.7276995305164319\n",
      "min real positive accuracy: 0.5116279069767442\n",
      "max real accuracy: 0.738\n",
      "min real accuracy: 0.56\n",
      "max estimate positive accuracy: 0.7197802197802198\n",
      "max estimate accuracy: 0.678\n",
      "real positive accuracy: [0.7276995305164319, 0.6693877551020408, 0.7197802197802198, 0.6175438596491228, 0.5451612903225806, 0.7063829787234043, 0.6258278145695364, 0.6148148148148148, 0.5116279069767442, 0.5423728813559322]\n",
      "estimate positive accuracy: [0.9671361502347418, 0.9795918367346939, 0.9945054945054945, 0.9228070175438596, 0.7354838709677419, 0.9659574468085106, 0.8543046357615894, 0.937037037037037, 0.6569767441860465, 0.7598870056497176]\n",
      "real accuracy: [0.738, 0.71, 0.704, 0.678, 0.6, 0.738, 0.696, 0.668, 0.56, 0.604]\n",
      "estimate accuracy: [0.856, 0.928, 0.818, 0.94, 0.75, 0.896, 0.886, 0.93, 0.674, 0.826]\n",
      "--------------------------------------------------\n",
      "threshold: 0.6\n",
      "precision = 0.6589\n",
      "recall = 0.7456\n",
      "accuracy = 0.708\n",
      "0\n",
      "precision = 0.7277\n",
      "recall = 0.6798\n",
      "accuracy = 0.738\n",
      "1\n",
      "precision = 0.6694\n",
      "recall = 0.7193\n",
      "accuracy = 0.71\n",
      "2\n",
      "precision = 0.7198\n",
      "recall = 0.5746\n",
      "accuracy = 0.704\n",
      "3\n",
      "precision = 0.6175\n",
      "recall = 0.7719\n",
      "accuracy = 0.678\n",
      "4\n",
      "precision = 0.5452\n",
      "recall = 0.7412\n",
      "accuracy = 0.6\n",
      "5\n",
      "precision = 0.7064\n",
      "recall = 0.7281\n",
      "accuracy = 0.738\n",
      "6\n",
      "precision = 0.6258\n",
      "recall = 0.8289\n",
      "accuracy = 0.696\n",
      "7\n",
      "precision = 0.6148\n",
      "recall = 0.7281\n",
      "accuracy = 0.668\n",
      "8\n",
      "precision = 0.5116\n",
      "recall = 0.7719\n",
      "accuracy = 0.56\n",
      "9\n",
      "precision = 0.5424\n",
      "recall = 0.8421\n",
      "accuracy = 0.604\n",
      "max real positive accuracy: 0.7276995305164319\n",
      "min real positive accuracy: 0.5116279069767442\n",
      "max real accuracy: 0.738\n",
      "min real accuracy: 0.56\n",
      "max estimate positive accuracy: 0.7197802197802198\n",
      "max estimate accuracy: 0.71\n",
      "real positive accuracy: [0.7276995305164319, 0.6693877551020408, 0.7197802197802198, 0.6175438596491228, 0.5451612903225806, 0.7063829787234043, 0.6258278145695364, 0.6148148148148148, 0.5116279069767442, 0.5423728813559322]\n",
      "estimate positive accuracy: [0.9671361502347418, 0.9714285714285714, 0.9945054945054945, 0.8842105263157894, 0.7064516129032258, 0.9531914893617022, 0.8211920529801324, 0.9, 0.6366279069767442, 0.7231638418079096]\n",
      "real accuracy: [0.738, 0.71, 0.704, 0.678, 0.6, 0.738, 0.696, 0.668, 0.56, 0.604]\n",
      "estimate accuracy: [0.882, 0.946, 0.844, 0.922, 0.74, 0.91, 0.872, 0.916, 0.672, 0.8]\n",
      "--------------------------------------------------\n",
      "threshold: 0.7\n",
      "precision = 0.6907\n",
      "recall = 0.7149\n",
      "accuracy = 0.724\n",
      "0\n",
      "precision = 0.7277\n",
      "recall = 0.6798\n",
      "accuracy = 0.738\n",
      "1\n",
      "precision = 0.6694\n",
      "recall = 0.7193\n",
      "accuracy = 0.71\n",
      "2\n",
      "precision = 0.7198\n",
      "recall = 0.5746\n",
      "accuracy = 0.704\n",
      "3\n",
      "precision = 0.6175\n",
      "recall = 0.7719\n",
      "accuracy = 0.678\n",
      "4\n",
      "precision = 0.5452\n",
      "recall = 0.7412\n",
      "accuracy = 0.6\n",
      "5\n",
      "precision = 0.7064\n",
      "recall = 0.7281\n",
      "accuracy = 0.738\n",
      "6\n",
      "precision = 0.6258\n",
      "recall = 0.8289\n",
      "accuracy = 0.696\n",
      "7\n",
      "precision = 0.6148\n",
      "recall = 0.7281\n",
      "accuracy = 0.668\n",
      "8\n",
      "precision = 0.5116\n",
      "recall = 0.7719\n",
      "accuracy = 0.56\n",
      "9\n",
      "precision = 0.5424\n",
      "recall = 0.8421\n",
      "accuracy = 0.604\n",
      "max real positive accuracy: 0.7276995305164319\n",
      "min real positive accuracy: 0.5116279069767442\n",
      "max real accuracy: 0.738\n",
      "min real accuracy: 0.56\n",
      "max estimate positive accuracy: 0.7197802197802198\n",
      "max estimate accuracy: 0.71\n",
      "real positive accuracy: [0.7276995305164319, 0.6693877551020408, 0.7197802197802198, 0.6175438596491228, 0.5451612903225806, 0.7063829787234043, 0.6258278145695364, 0.6148148148148148, 0.5116279069767442, 0.5423728813559322]\n",
      "estimate positive accuracy: [0.9436619718309859, 0.9306122448979591, 0.978021978021978, 0.8105263157894737, 0.6709677419354839, 0.9191489361702128, 0.7516556291390728, 0.8296296296296296, 0.6017441860465116, 0.6610169491525424]\n",
      "real accuracy: [0.738, 0.71, 0.704, 0.678, 0.6, 0.738, 0.696, 0.668, 0.56, 0.604]\n",
      "estimate accuracy: [0.906, 0.95, 0.876, 0.882, 0.74, 0.922, 0.832, 0.884, 0.668, 0.756]\n",
      "--------------------------------------------------\n",
      "threshold: 0.8\n",
      "precision = 0.7282\n",
      "recall = 0.6579\n",
      "accuracy = 0.732\n",
      "0\n",
      "precision = 0.7277\n",
      "recall = 0.6798\n",
      "accuracy = 0.738\n",
      "1\n",
      "precision = 0.6694\n",
      "recall = 0.7193\n",
      "accuracy = 0.71\n",
      "2\n",
      "precision = 0.7198\n",
      "recall = 0.5746\n",
      "accuracy = 0.704\n",
      "3\n",
      "precision = 0.6175\n",
      "recall = 0.7719\n",
      "accuracy = 0.678\n",
      "4\n",
      "precision = 0.5452\n",
      "recall = 0.7412\n",
      "accuracy = 0.6\n",
      "5\n",
      "precision = 0.7064\n",
      "recall = 0.7281\n",
      "accuracy = 0.738\n",
      "6\n",
      "precision = 0.6258\n",
      "recall = 0.8289\n",
      "accuracy = 0.696\n",
      "7\n",
      "precision = 0.6148\n",
      "recall = 0.7281\n",
      "accuracy = 0.668\n",
      "8\n",
      "precision = 0.5116\n",
      "recall = 0.7719\n",
      "accuracy = 0.56\n",
      "9\n",
      "precision = 0.5424\n",
      "recall = 0.8421\n",
      "accuracy = 0.604\n",
      "max real positive accuracy: 0.7276995305164319\n",
      "min real positive accuracy: 0.5116279069767442\n",
      "max real accuracy: 0.738\n",
      "min real accuracy: 0.56\n",
      "max estimate positive accuracy: 0.7197802197802198\n",
      "max estimate accuracy: 0.738\n",
      "real positive accuracy: [0.7276995305164319, 0.6693877551020408, 0.7197802197802198, 0.6175438596491228, 0.5451612903225806, 0.7063829787234043, 0.6258278145695364, 0.6148148148148148, 0.5116279069767442, 0.5423728813559322]\n",
      "estimate positive accuracy: [0.8685446009389671, 0.8204081632653061, 0.9340659340659341, 0.7157894736842105, 0.6096774193548387, 0.8382978723404255, 0.6721854304635762, 0.7555555555555555, 0.5377906976744186, 0.5819209039548022]\n",
      "real accuracy: [0.738, 0.71, 0.704, 0.678, 0.6, 0.738, 0.696, 0.668, 0.56, 0.604]\n",
      "estimate accuracy: [0.902, 0.902, 0.904, 0.834, 0.724, 0.906, 0.796, 0.864, 0.64, 0.704]\n",
      "--------------------------------------------------\n",
      "threshold: 0.9\n",
      "precision = 0.7738\n",
      "recall = 0.5702\n",
      "accuracy = 0.728\n",
      "0\n",
      "precision = 0.7277\n",
      "recall = 0.6798\n",
      "accuracy = 0.738\n",
      "1\n",
      "precision = 0.6694\n",
      "recall = 0.7193\n",
      "accuracy = 0.71\n",
      "2\n",
      "precision = 0.7198\n",
      "recall = 0.5746\n",
      "accuracy = 0.704\n",
      "3\n",
      "precision = 0.6175\n",
      "recall = 0.7719\n",
      "accuracy = 0.678\n",
      "4\n",
      "precision = 0.5452\n",
      "recall = 0.7412\n",
      "accuracy = 0.6\n",
      "5\n",
      "precision = 0.7064\n",
      "recall = 0.7281\n",
      "accuracy = 0.738\n",
      "6\n",
      "precision = 0.6258\n",
      "recall = 0.8289\n",
      "accuracy = 0.696\n",
      "7\n",
      "precision = 0.6148\n",
      "recall = 0.7281\n",
      "accuracy = 0.668\n",
      "8\n",
      "precision = 0.5116\n",
      "recall = 0.7719\n",
      "accuracy = 0.56\n",
      "9\n",
      "precision = 0.5424\n",
      "recall = 0.8421\n",
      "accuracy = 0.604\n",
      "max real positive accuracy: 0.7276995305164319\n",
      "min real positive accuracy: 0.5116279069767442\n",
      "max real accuracy: 0.738\n",
      "min real accuracy: 0.56\n",
      "max estimate positive accuracy: 0.7197802197802198\n",
      "max estimate accuracy: 0.704\n",
      "real positive accuracy: [0.7276995305164319, 0.6693877551020408, 0.7197802197802198, 0.6175438596491228, 0.5451612903225806, 0.7063829787234043, 0.6258278145695364, 0.6148148148148148, 0.5116279069767442, 0.5423728813559322]\n",
      "estimate positive accuracy: [0.7605633802816901, 0.6816326530612244, 0.8296703296703297, 0.5894736842105263, 0.5225806451612903, 0.7106382978723405, 0.5562913907284768, 0.6222222222222222, 0.4622093023255814, 0.4745762711864407]\n",
      "real accuracy: [0.738, 0.71, 0.704, 0.678, 0.6, 0.738, 0.696, 0.668, 0.56, 0.604]\n",
      "estimate accuracy: [0.886, 0.842, 0.904, 0.766, 0.692, 0.862, 0.732, 0.796, 0.612, 0.628]\n",
      "--------------------------------------------------\n",
      "threshold: 1.0\n",
      "precision = 0.8203\n",
      "recall = 0.4605\n",
      "accuracy = 0.708\n",
      "0\n",
      "precision = 0.7277\n",
      "recall = 0.6798\n",
      "accuracy = 0.738\n",
      "1\n",
      "precision = 0.6694\n",
      "recall = 0.7193\n",
      "accuracy = 0.71\n",
      "2\n",
      "precision = 0.7198\n",
      "recall = 0.5746\n",
      "accuracy = 0.704\n",
      "3\n",
      "precision = 0.6175\n",
      "recall = 0.7719\n",
      "accuracy = 0.678\n",
      "4\n",
      "precision = 0.5452\n",
      "recall = 0.7412\n",
      "accuracy = 0.6\n",
      "5\n",
      "precision = 0.7064\n",
      "recall = 0.7281\n",
      "accuracy = 0.738\n",
      "6\n",
      "precision = 0.6258\n",
      "recall = 0.8289\n",
      "accuracy = 0.696\n",
      "7\n",
      "precision = 0.6148\n",
      "recall = 0.7281\n",
      "accuracy = 0.668\n",
      "8\n",
      "precision = 0.5116\n",
      "recall = 0.7719\n",
      "accuracy = 0.56\n",
      "9\n",
      "precision = 0.5424\n",
      "recall = 0.8421\n",
      "accuracy = 0.604\n",
      "max real positive accuracy: 0.7276995305164319\n",
      "min real positive accuracy: 0.5116279069767442\n",
      "max real accuracy: 0.738\n",
      "min real accuracy: 0.56\n",
      "max estimate positive accuracy: 0.7197802197802198\n",
      "max estimate accuracy: 0.704\n",
      "real positive accuracy: [0.7276995305164319, 0.6693877551020408, 0.7197802197802198, 0.6175438596491228, 0.5451612903225806, 0.7063829787234043, 0.6258278145695364, 0.6148148148148148, 0.5116279069767442, 0.5423728813559322]\n",
      "estimate positive accuracy: [0.6009389671361502, 0.5224489795918368, 0.7032967032967034, 0.44912280701754387, 0.4129032258064516, 0.5446808510638298, 0.423841059602649, 0.4740740740740741, 0.37209302325581395, 0.3615819209039548]\n",
      "real accuracy: [0.738, 0.71, 0.704, 0.678, 0.6, 0.738, 0.696, 0.668, 0.56, 0.604]\n",
      "estimate accuracy: [0.83, 0.766, 0.892, 0.686, 0.636, 0.786, 0.652, 0.716, 0.568, 0.548]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyze(df, threshold):\n",
    "    df[\"hypothesis\"] = df[\"result\"].apply(lambda x: 1 if x >= threshold else 0)\n",
    "\n",
    "    count_true_positive = len(df[(df['hypothesis'] == 1) & (df['label'] == 0)])\n",
    "    count_true_negative = len(df[(df['hypothesis'] == 0) & (df['label'] != 0)])\n",
    "    count_false_positive = len(df[(df['hypothesis'] == 1) & (df['label'] != 0)])\n",
    "    count_false_negative = len(df[(df['hypothesis'] == 0) & (df['label'] == 0)])\n",
    "    # print(\"true positive: {count}\".format(count=count_true_positive))\n",
    "    # print(\"true negative: {count}\".format(count=count_true_negative))\n",
    "    # print(\"false positive: {count}\".format(count=count_false_positive))\n",
    "    # print(\"false negative: {count}\".format(count=count_false_negative))\n",
    "\n",
    "    print(\"precision = {}\".format(round(count_true_positive / (count_true_positive + count_false_positive), 4)))\n",
    "    print(\"recall = {}\".format(round(count_true_positive / (count_true_positive + count_false_negative), 4)))\n",
    "    print(\"accuracy = {}\".format(round((count_true_positive + count_true_negative) / (count_true_positive + count_true_negative + count_false_positive + count_false_negative), 4)))\n",
    "\n",
    "    real_positive_accuarcy = []\n",
    "    estimate_positive_accuracy = []\n",
    "    real_accuracy = []\n",
    "    estimate_accuracy = []\n",
    "    for prompt_id in range(10):\n",
    "        print(prompt_id)\n",
    "        real_count_true_positive = len(df[(df['prompt{}'.format(prompt_id)] == 1) & (df['label'] == 0)])\n",
    "        real_count_true_negative = len(df[(df['prompt{}'.format(prompt_id)] == 0) & (df['label'] != 0)])\n",
    "        real_count_false_positive = len(df[(df['prompt{}'.format(prompt_id)] == 1) & (df['label'] != 0)])\n",
    "        real_count_false_negative = len(df[(df['prompt{}'.format(prompt_id)] == 0) & (df['label'] == 0)])\n",
    "        # print(\"prompt {prompt_id} real true positive: {count}\".format(prompt_id=prompt_id, count=real_count_true_positive))\n",
    "        # print(\"prompt {prompt_id} real true negative: {count}\".format(prompt_id=prompt_id, count=real_count_true_negative))\n",
    "        # print(\"prompt {prompt_id} real false positive: {count}\".format(prompt_id=prompt_id, count=real_count_false_positive))\n",
    "        # print(\"prompt {prompt_id} real false negative: {count}\".format(prompt_id=prompt_id, count=real_count_false_negative))\n",
    "        print(\"precision = {}\".format(round(real_count_true_positive / (real_count_true_positive + real_count_false_positive), 4)))\n",
    "        print(\"recall = {}\".format(round(real_count_true_positive / (real_count_true_positive + real_count_false_negative), 4)))\n",
    "        print(\"accuracy = {}\".format(round((real_count_true_positive + real_count_true_negative) / (real_count_true_positive + real_count_true_negative + real_count_false_positive + real_count_false_negative), 4)))\n",
    "        # print(\"prompt {prompt_id}\".format(prompt_id=prompt_id), round(real_count_true_positive / (real_count_true_positive + real_count_false_positive), 4))\n",
    "        real_positive_accuarcy.append(real_count_true_positive / (real_count_true_positive + real_count_false_positive))\n",
    "        real_accuracy.append((real_count_true_positive + real_count_true_negative) / (real_count_true_positive + real_count_true_negative + real_count_false_positive + real_count_false_negative))\n",
    "        estimate_count_true_positive = len(df[(df['prompt{}'.format(prompt_id)] == 1) & (df['hypothesis'] == 1)])\n",
    "        estimate_count_true_negative = len(df[(df['prompt{}'.format(prompt_id)] == 0) & (df['hypothesis'] == 0)])\n",
    "        estimate_count_false_positive = len(df[(df['prompt{}'.format(prompt_id)] == 1) & (df['hypothesis'] == 0)])\n",
    "        estimate_count_false_negative = len(df[(df['prompt{}'.format(prompt_id)] == 0) & (df['hypothesis'] == 1)])\n",
    "        # print(\"prompt {prompt_id} estimate true positive: {count}\".format(prompt_id=prompt_id, count=estimate_count_true_positive))\n",
    "        # print(\"prompt {prompt_id} estimate true negative: {count}\".format(prompt_id=prompt_id, count=estimate_count_true_negative))\n",
    "        # print(\"prompt {prompt_id} estimate false positive: {count}\".format(prompt_id=prompt_id, count=estimate_count_false_positive))\n",
    "        # print(\"prompt {prompt_id} estimate false negative: {count}\".format(prompt_id=prompt_id, count=estimate_count_false_negative))\n",
    "\n",
    "        # print(\"prompt {prompt_id}\".format(prompt_id=prompt_id), round(estimate_count_true_positive / (estimate_count_true_positive + estimate_count_false_positive), 4))\n",
    "        estimate_positive_accuracy.append(estimate_count_true_positive / (estimate_count_true_positive + estimate_count_false_positive))\n",
    "        estimate_accuracy.append((estimate_count_true_positive + estimate_count_true_negative) / (estimate_count_true_positive + estimate_count_true_negative + estimate_count_false_positive + estimate_count_false_negative))\n",
    "    print(\"max real positive accuracy: {}\".format(max(real_positive_accuarcy)))\n",
    "    print(\"min real positive accuracy: {}\".format(min(real_positive_accuarcy)))\n",
    "    print(\"max real accuracy: {}\".format(max(real_accuracy)))\n",
    "    print(\"min real accuracy: {}\".format(min(real_accuracy)))\n",
    "\n",
    "    index_max_estimate_positive_accuracy = estimate_positive_accuracy.index(max(estimate_positive_accuracy))\n",
    "    print(\"max estimate positive accuracy: {}\".format(real_positive_accuarcy[index_max_estimate_positive_accuracy]))\n",
    "    index_max_estimate_accuracy = estimate_accuracy.index(max(estimate_accuracy))\n",
    "    print(\"max estimate accuracy: {}\".format(real_accuracy[index_max_estimate_accuracy]))\n",
    "    print(\"real positive accuracy: {}\".format(real_positive_accuarcy))\n",
    "    print(\"estimate positive accuracy: {}\".format(estimate_positive_accuracy))\n",
    "    print(\"real accuracy: {}\".format(real_accuracy))\n",
    "    print(\"estimate accuracy: {}\".format(estimate_accuracy))\n",
    "    \n",
    "test_df = df\n",
    "# test_df = df.sample(n=300)\n",
    "for threshold in [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    print(\"threshold: {threshold}\".format(threshold=threshold))\n",
    "    analyze(test_df, threshold)\n",
    "    print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "m = 500\n",
    "n = 10\n",
    "# test_df = df\n",
    "m = test_df.shape[0]\n",
    "X = np.array([[1 if row[\"prompt{}\".format(i)] == 1 else -1 for i in range(10)] for index, row in test_df.iterrows()])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33096849 0.36536063 0.30150423 0.36069314 0.24907924 0.34832095\n",
      "  0.33338407 0.35669106 0.16787392 0.29333269]]\n",
      "(500,)\n",
      "true positive: 171\n",
      "true negative: 179\n",
      "false positive: 93\n",
      "false negative: 57\n",
      "precision: 0.6477272727272727\n",
      "recall: 0.75\n",
      "accuracy: 0.7\n",
      "[[0.80720182 0.89108109 0.73534118 0.87969751 0.60748143 0.84952288\n",
      "  0.8130932  0.86993679 0.40942911 0.71541156]]\n"
     ]
    }
   ],
   "source": [
    "# SVD to find first singular vector\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "# U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "# print(Vt)\n",
    "U, s, Vt = randomized_svd(X, n_components=1)\n",
    "print(Vt)\n",
    "Vt = Vt * s[0] * np.sign(Vt[0][0])\n",
    "w_hat = Vt / np.sqrt(m)\n",
    "w_tilde = w_hat\n",
    "w_tilde[w_tilde > 1] = 1\n",
    "w_tilde[w_tilde < -1] = -1\n",
    "\n",
    "q_hat = np.sign(np.matmul(X, w_tilde[0]))\n",
    "\n",
    "print(q_hat.shape)\n",
    "\n",
    "test_df[\"estimate_result\"] = q_hat\n",
    "\n",
    "count_true_positive = len(test_df[(test_df['estimate_result'] == 1) & (test_df['label'] == 0)])\n",
    "count_true_negative = len(test_df[(test_df['estimate_result'] == -1) & (test_df['label'] != 0)])\n",
    "count_false_positive = len(test_df[(test_df['estimate_result'] == 1) & (test_df['label'] != 0)])\n",
    "count_false_negative = len(test_df[(test_df['estimate_result'] == -1) & (test_df['label'] == 0)])\n",
    "print(\"true positive: {count}\".format(count=count_true_positive))\n",
    "print(\"true negative: {count}\".format(count=count_true_negative))\n",
    "print(\"false positive: {count}\".format(count=count_false_positive))\n",
    "print(\"false negative: {count}\".format(count=count_false_negative))\n",
    "\n",
    "print(\"precision: {precision}\".format(precision=count_true_positive / (count_true_positive + count_false_positive)))\n",
    "print(\"recall: {recall}\".format(recall=count_true_positive / (count_true_positive + count_false_negative)))\n",
    "print(\"accuracy: {accuracy}\".format(accuracy=(count_true_positive + count_true_negative) / len(test_df)))\n",
    "\n",
    "print(w_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.7\n",
      "true positive / true positive + false positive = 0.6757\n",
      "accuracy = 0.76\n",
      "max real positive accuracy: 0.6956521739130435\n",
      "min real positive accuracy: 0.41935483870967744\n",
      "max real accuracy: 0.77\n",
      "min real accuracy: 0.53\n",
      "max estimate positive accuracy: 0.6956521739130435\n",
      "max estimate accuracy: 0.77\n",
      "real positive accuracy: [0.6944444444444444, 0.5952380952380952, 0.6956521739130435, 0.5777777777777777, 0.4807692307692308, 0.6486486486486487, 0.6222222222222222, 0.5909090909090909, 0.41935483870967744, 0.4393939393939394]\n",
      "estimate positive accuracy: [0.9444444444444444, 0.8809523809523809, 1.0, 0.8, 0.6346153846153846, 0.918918918918919, 0.8, 0.8409090909090909, 0.5, 0.5606060606060606]\n",
      "real accuracy: [0.77, 0.71, 0.72, 0.7, 0.61, 0.74, 0.74, 0.71, 0.53, 0.55]\n",
      "estimate accuracy: [0.95, 0.95, 0.86, 0.9, 0.77, 0.94, 0.9, 0.93, 0.63, 0.71]\n",
      "--------------------------------------------------\n",
      "(100, 10)\n",
      "(100,)\n",
      "true positive: 25\n",
      "true negative: 49\n",
      "false positive: 14\n",
      "false negative: 12\n",
      "precision: 0.6410256410256411\n",
      "recall: 0.6756756756756757\n",
      "accuracy: 0.74\n",
      "[[0.88471193 0.94384847 0.69670089 0.88585504 0.63698487 0.88219829\n",
      "  0.86510873 0.91310543 0.33331499 0.59175757]]\n"
     ]
    }
   ],
   "source": [
    "test_df = df.sample(n=100)\n",
    "for threshold in [0.7]:\n",
    "    print(\"threshold: {threshold}\".format(threshold=threshold))\n",
    "    analyze(test_df, threshold)\n",
    "    print(\"--------------------------------------------------\")\n",
    "n = 10\n",
    "# test_df = df\n",
    "m = test_df.shape[0]\n",
    "X = np.array([[1 if row[\"prompt{}\".format(i)] == 1 else -1 for i in range(10)] for index, row in test_df.iterrows()])\n",
    "print(X.shape)\n",
    "# SVD to find first singular vector\n",
    "# U, s, V = np.linalg.svd(X, full_matrices=False)\n",
    "U, s, Vt = randomized_svd(X, n_components=1)\n",
    "Vt = Vt * s[0] * np.sign(Vt[0][0])\n",
    "w_hat = Vt / np.sqrt(m)\n",
    "w_tilde = w_hat\n",
    "w_tilde[w_tilde > 1] = 1\n",
    "w_tilde[w_tilde < -1] = -1\n",
    "\n",
    "q_hat = np.sign(np.matmul(X, w_tilde[0]))\n",
    "\n",
    "print(q_hat.shape)\n",
    "\n",
    "test_df[\"estimate_result\"] = q_hat\n",
    "\n",
    "count_true_positive = len(test_df[(test_df['estimate_result'] == 1) & (test_df['label'] == 0)])\n",
    "count_true_negative = len(test_df[(test_df['estimate_result'] == -1) & (test_df['label'] != 0)])\n",
    "count_false_positive = len(test_df[(test_df['estimate_result'] == 1) & (test_df['label'] != 0)])\n",
    "count_false_negative = len(test_df[(test_df['estimate_result'] == -1) & (test_df['label'] == 0)])\n",
    "print(\"true positive: {count}\".format(count=count_true_positive))\n",
    "print(\"true negative: {count}\".format(count=count_true_negative))\n",
    "print(\"false positive: {count}\".format(count=count_false_positive))\n",
    "print(\"false negative: {count}\".format(count=count_false_negative))\n",
    "\n",
    "print(\"precision: {precision}\".format(precision=count_true_positive / (count_true_positive + count_false_positive)))\n",
    "print(\"recall: {recall}\".format(recall=count_true_positive / (count_true_positive + count_false_negative)))\n",
    "print(\"accuracy: {accuracy}\".format(accuracy=(count_true_positive + count_true_negative) / len(test_df)))\n",
    "\n",
    "print(w_hat)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
