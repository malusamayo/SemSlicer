{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 87 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             400 non-null    int64  \n",
      " 1   text                   400 non-null    object \n",
      " 2   label                  400 non-null    int64  \n",
      " 3   anger_result           400 non-null    float64\n",
      " 4   anger_prompt0_meta     400 non-null    object \n",
      " 5   anger_prompt0          400 non-null    int64  \n",
      " 6   anger_prompt1_meta     400 non-null    object \n",
      " 7   anger_prompt1          400 non-null    int64  \n",
      " 8   anger_prompt2_meta     400 non-null    object \n",
      " 9   anger_prompt2          400 non-null    int64  \n",
      " 10  anger_prompt3_meta     400 non-null    object \n",
      " 11  anger_prompt3          400 non-null    int64  \n",
      " 12  anger_prompt4_meta     400 non-null    object \n",
      " 13  anger_prompt4          400 non-null    int64  \n",
      " 14  anger_prompt5_meta     400 non-null    object \n",
      " 15  anger_prompt5          400 non-null    int64  \n",
      " 16  anger_prompt6_meta     400 non-null    object \n",
      " 17  anger_prompt6          400 non-null    int64  \n",
      " 18  anger_prompt7_meta     400 non-null    object \n",
      " 19  anger_prompt7          400 non-null    int64  \n",
      " 20  anger_prompt8_meta     400 non-null    object \n",
      " 21  anger_prompt8          400 non-null    int64  \n",
      " 22  anger_prompt9_meta     400 non-null    object \n",
      " 23  anger_prompt9          400 non-null    int64  \n",
      " 24  joy_result             400 non-null    float64\n",
      " 25  joy_prompt0_meta       400 non-null    object \n",
      " 26  joy_prompt0            400 non-null    int64  \n",
      " 27  joy_prompt1_meta       400 non-null    object \n",
      " 28  joy_prompt1            400 non-null    int64  \n",
      " 29  joy_prompt2_meta       400 non-null    object \n",
      " 30  joy_prompt2            400 non-null    int64  \n",
      " 31  joy_prompt3_meta       400 non-null    object \n",
      " 32  joy_prompt3            400 non-null    int64  \n",
      " 33  joy_prompt4_meta       400 non-null    object \n",
      " 34  joy_prompt4            400 non-null    int64  \n",
      " 35  joy_prompt5_meta       400 non-null    object \n",
      " 36  joy_prompt5            400 non-null    int64  \n",
      " 37  joy_prompt6_meta       400 non-null    object \n",
      " 38  joy_prompt6            400 non-null    int64  \n",
      " 39  joy_prompt7_meta       400 non-null    object \n",
      " 40  joy_prompt7            400 non-null    int64  \n",
      " 41  joy_prompt8_meta       400 non-null    object \n",
      " 42  joy_prompt8            400 non-null    int64  \n",
      " 43  joy_prompt9_meta       400 non-null    object \n",
      " 44  joy_prompt9            400 non-null    int64  \n",
      " 45  optimism_result        400 non-null    float64\n",
      " 46  optimism_prompt0_meta  400 non-null    object \n",
      " 47  optimism_prompt0       400 non-null    int64  \n",
      " 48  optimism_prompt1_meta  400 non-null    object \n",
      " 49  optimism_prompt1       400 non-null    int64  \n",
      " 50  optimism_prompt2_meta  400 non-null    object \n",
      " 51  optimism_prompt2       400 non-null    int64  \n",
      " 52  optimism_prompt3_meta  400 non-null    object \n",
      " 53  optimism_prompt3       400 non-null    int64  \n",
      " 54  optimism_prompt4_meta  400 non-null    object \n",
      " 55  optimism_prompt4       400 non-null    int64  \n",
      " 56  optimism_prompt5_meta  400 non-null    object \n",
      " 57  optimism_prompt5       400 non-null    int64  \n",
      " 58  optimism_prompt6_meta  400 non-null    object \n",
      " 59  optimism_prompt6       400 non-null    int64  \n",
      " 60  optimism_prompt7_meta  400 non-null    object \n",
      " 61  optimism_prompt7       400 non-null    int64  \n",
      " 62  optimism_prompt8_meta  400 non-null    object \n",
      " 63  optimism_prompt8       400 non-null    int64  \n",
      " 64  optimism_prompt9_meta  400 non-null    object \n",
      " 65  optimism_prompt9       400 non-null    int64  \n",
      " 66  sadness_result         400 non-null    float64\n",
      " 67  sadness_prompt0_meta   400 non-null    object \n",
      " 68  sadness_prompt0        400 non-null    int64  \n",
      " 69  sadness_prompt1_meta   400 non-null    object \n",
      " 70  sadness_prompt1        400 non-null    int64  \n",
      " 71  sadness_prompt2_meta   400 non-null    object \n",
      " 72  sadness_prompt2        400 non-null    int64  \n",
      " 73  sadness_prompt3_meta   400 non-null    object \n",
      " 74  sadness_prompt3        400 non-null    int64  \n",
      " 75  sadness_prompt4_meta   400 non-null    object \n",
      " 76  sadness_prompt4        400 non-null    int64  \n",
      " 77  sadness_prompt5_meta   400 non-null    object \n",
      " 78  sadness_prompt5        400 non-null    int64  \n",
      " 79  sadness_prompt6_meta   400 non-null    object \n",
      " 80  sadness_prompt6        400 non-null    int64  \n",
      " 81  sadness_prompt7_meta   400 non-null    object \n",
      " 82  sadness_prompt7        400 non-null    int64  \n",
      " 83  sadness_prompt8_meta   400 non-null    object \n",
      " 84  sadness_prompt8        400 non-null    int64  \n",
      " 85  sadness_prompt9_meta   400 non-null    object \n",
      " 86  sadness_prompt9        400 non-null    int64  \n",
      "dtypes: float64(4), int64(42), object(41)\n",
      "memory usage: 272.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = read_csv_file('result_emotion.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "key =\"joy\"\n",
    "prompt_num = 10\n",
    "golden_label = 1\n",
    "\n",
    "for i in range(prompt_num):\n",
    "    df[\"{key}_prompt{id}\".format(key=key, id=i)] = df[\"{key}_prompt{id}_meta\".format(key=key, id=i)].apply(\n",
    "        lambda x: 1 \n",
    "            if x.find(\"My Answer is Yes\") != -1 \n",
    "            else 0 if x.find(\"My Answer is No\") != -1\n",
    "            else 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.8\n",
      "precision = 0.5\n",
      "recall = 0.1744\n",
      "accuracy = 0.785\n",
      "max real precision: 0.4773\n",
      "min real precision: 0.23\n",
      "max real recall: 0.7326\n",
      "min real recall: 0.0814\n",
      "max real accuracy: 0.775\n",
      "min real accuracy: 0.5825\n",
      "max estimate precision: 0.3333\n",
      "max estimate accuracy: 0.7675\n",
      "real precision: [0.2324, 0.3378, 0.2834, 0.3539, 0.2349, 0.2874, 0.3067, 0.3333, 0.4773, 0.23]\n",
      "real recall: [0.3837, 0.5814, 0.6163, 0.7326, 0.407, 0.5581, 0.5814, 0.0814, 0.4884, 0.2674]\n",
      "real accuracy: [0.595, 0.665, 0.5825, 0.655, 0.5875, 0.6075, 0.6275, 0.7675, 0.775, 0.65]\n",
      "0.2324\n",
      "0.3378\n",
      "0.2834\n",
      "0.3539\n",
      "0.2349\n",
      "0.2874\n",
      "0.3067\n",
      "0.3333\n",
      "0.4773\n",
      "0.23\n",
      "----\n",
      "0.3837\n",
      "0.5814\n",
      "0.6163\n",
      "0.7326\n",
      "0.407\n",
      "0.5581\n",
      "0.5814\n",
      "0.0814\n",
      "0.4884\n",
      "0.2674\n",
      "----\n",
      "0.595\n",
      "0.665\n",
      "0.5825\n",
      "0.655\n",
      "0.5875\n",
      "0.6075\n",
      "0.6275\n",
      "0.7675\n",
      "0.775\n",
      "0.65\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyze(df, threshold, key, golden_label):\n",
    "    df[\"{}_hypothesis\".format(key)] = df[\"{}_result\".format(key)].apply(lambda x: 1 if x >= threshold else 0)\n",
    "\n",
    "    count_true_positive = len(df[(df[\"{}_hypothesis\".format(key)] == 1) & (df['label'] == golden_label)])\n",
    "    count_true_negative = len(df[(df[\"{}_hypothesis\".format(key)] == 0) & (df['label'] != golden_label)])\n",
    "    count_false_positive = len(df[(df[\"{}_hypothesis\".format(key)] == 1) & (df['label'] != golden_label)])\n",
    "    count_false_negative = len(df[(df[\"{}_hypothesis\".format(key)] == 0) & (df['label'] == golden_label)])\n",
    "\n",
    "    print(\"precision = {}\".format(round(0 if count_true_positive == 0 else count_true_positive / (count_true_positive + count_false_positive), 4)))\n",
    "    print(\"recall = {}\".format(round(count_true_positive / (count_true_positive + count_false_negative), 4)))\n",
    "    print(\"accuracy = {}\".format(round((count_true_positive + count_true_negative) / (count_true_positive + count_true_negative + count_false_positive + count_false_negative), 4)))\n",
    "\n",
    "    real_precision = []\n",
    "    estimate_precision = []\n",
    "    real_recall = []\n",
    "    estimate_recall = []\n",
    "    real_accuracy = []\n",
    "    estimate_accuracy = []\n",
    "    for prompt_id in range(10):\n",
    "        real_count_true_positive = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 1) & (df['label'] == golden_label)])\n",
    "        real_count_true_negative = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 0) & (df['label'] != golden_label)])\n",
    "        real_count_false_positive = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 1) & (df['label'] != golden_label)])\n",
    "        real_count_false_negative = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 0) & (df['label'] == golden_label)])\n",
    "        # print(\"precision = {}\".format(round(real_count_true_positive / (real_count_true_positive + real_count_false_positive), 4)))\n",
    "        # print(\"recall = {}\".format(round(real_count_true_positive / (real_count_true_positive + real_count_false_negative), 4)))\n",
    "        # print(\"accuracy = {}\".format(round((real_count_true_positive + real_count_true_negative) / (real_count_true_positive + real_count_true_negative + real_count_false_positive + real_count_false_negative), 4)))\n",
    "        # print(\"prompt {prompt_id}\".format(prompt_id=prompt_id), round(real_count_true_positive / (real_count_true_positive + real_count_false_positive), 4))\n",
    "        real_precision.append(round(real_count_true_positive / (real_count_true_positive + real_count_false_positive), 4))\n",
    "        real_recall.append(round(real_count_true_positive / (real_count_true_positive + real_count_false_negative), 4))\n",
    "        real_accuracy.append(round((real_count_true_positive + real_count_true_negative) / (real_count_true_positive + real_count_true_negative + real_count_false_positive + real_count_false_negative), 4))\n",
    "        estimate_count_true_positive = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 1) & (df[\"{}_hypothesis\".format(key)] == 1)])\n",
    "        estimate_count_true_negative = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 0) & (df[\"{}_hypothesis\".format(key)] == 0)])\n",
    "        estimate_count_false_positive = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 1) & (df[\"{}_hypothesis\".format(key)] == 0)])\n",
    "        estimate_count_false_negative = len(df[(df['{key}_prompt{id}'.format(key=key,id=prompt_id)] == 0) & (df[\"{}_hypothesis\".format(key)] == 1)])\n",
    "        # print(\"prompt {prompt_id}\".format(prompt_id=prompt_id), round(estimate_count_true_positive / (estimate_count_true_positive + estimate_count_false_positive), 4))\n",
    "        estimate_precision.append(round(estimate_count_true_positive / (estimate_count_true_positive + estimate_count_false_positive), 4))\n",
    "        estimate_recall.append(0 if estimate_count_true_positive == 0 else round(estimate_count_true_positive / (estimate_count_true_positive + estimate_count_false_negative), 4))\n",
    "        estimate_accuracy.append(round((estimate_count_true_positive + estimate_count_true_negative) / (estimate_count_true_positive + estimate_count_true_negative + estimate_count_false_positive + estimate_count_false_negative), 4))\n",
    "    print(\"max real precision: {}\".format(max(real_precision)))\n",
    "    print(\"min real precision: {}\".format(min(real_precision)))\n",
    "    print(\"max real recall: {}\".format(max(real_recall)))\n",
    "    print(\"min real recall: {}\".format(min(real_recall)))\n",
    "    print(\"max real accuracy: {}\".format(max(real_accuracy)))\n",
    "    print(\"min real accuracy: {}\".format(min(real_accuracy)))\n",
    "\n",
    "    index_max_estimate_precision = estimate_precision.index(max(estimate_precision))\n",
    "    print(\"max estimate precision: {}\".format(real_precision[index_max_estimate_precision]))\n",
    "    index_max_estimate_accuracy = estimate_accuracy.index(max(estimate_accuracy))\n",
    "    print(\"max estimate accuracy: {}\".format(real_accuracy[index_max_estimate_accuracy]))\n",
    "    print(\"real precision: {}\".format(real_precision))\n",
    "    print(\"real recall: {}\".format(real_recall))\n",
    "    # print(\"estimate precision: {}\".format(estimate_precision))\n",
    "    print(\"real accuracy: {}\".format(real_accuracy))\n",
    "    # print(\"estimate accuracy: {}\".format(estimate_accuracy))\n",
    "    for item in real_precision:\n",
    "        print(item)\n",
    "    print(\"----\")\n",
    "    for item in real_recall:\n",
    "        print(item)\n",
    "    print(\"----\")\n",
    "    for item in real_accuracy:\n",
    "        print(item)\n",
    "        \n",
    "    \n",
    "test_df = df\n",
    "# test_df = df.sample(n=300)\n",
    "for threshold in [0.8]:\n",
    "    print(\"threshold: {threshold}\".format(threshold=threshold))\n",
    "    analyze(test_df, threshold, key, golden_label)\n",
    "    print(\"--------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "m = 500\n",
    "n = 10\n",
    "# test_df = df\n",
    "m = test_df.shape[0]\n",
    "X = np.array([[1 if row[\"{key}_prompt{id}\".format(key=key, id=i)] == 1 else -1 for i in range(10)] for index, row in test_df.iterrows()])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1993306  -0.37854607 -0.33478588 -0.3339902  -0.15481116 -0.37139027\n",
      "  -0.3512498  -0.30495271 -0.39362548 -0.24521079]]\n",
      "(400,)\n",
      "true positive: 48\n",
      "true negative: 237\n",
      "false positive: 77\n",
      "false negative: 38\n",
      "precision: 0.384\n",
      "recall: 0.5581395348837209\n",
      "accuracy: 0.7125\n",
      "[[0.39075279 0.74207337 0.65628918 0.65472938 0.3034802  0.72804567\n",
      "  0.6885638  0.59780647 0.77163392 0.48069287]]\n"
     ]
    }
   ],
   "source": [
    "# SVD to find first singular vector\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "# U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "# print(Vt)\n",
    "U, s, Vt = randomized_svd(X, n_components=1)\n",
    "print(Vt)\n",
    "Vt = Vt * s[0] * np.sign(Vt[0][0])\n",
    "w_hat = Vt / np.sqrt(m)\n",
    "w_tilde = w_hat\n",
    "w_tilde[w_tilde > 1] = 1\n",
    "w_tilde[w_tilde < -1] = -1\n",
    "\n",
    "q_hat = np.sign(np.matmul(X, w_tilde[0]))\n",
    "\n",
    "print(q_hat.shape)\n",
    "\n",
    "test_df[\"estimate_result\"] = q_hat\n",
    "\n",
    "count_true_positive = len(test_df[(test_df['estimate_result'] == 1) & (test_df['label'] == golden_label)])\n",
    "count_true_negative = len(test_df[(test_df['estimate_result'] == -1) & (test_df['label'] != golden_label)])\n",
    "count_false_positive = len(test_df[(test_df['estimate_result'] == 1) & (test_df['label'] != golden_label)])\n",
    "count_false_negative = len(test_df[(test_df['estimate_result'] == -1) & (test_df['label'] == golden_label)])\n",
    "print(\"true positive: {count}\".format(count=count_true_positive))\n",
    "print(\"true negative: {count}\".format(count=count_true_negative))\n",
    "print(\"false positive: {count}\".format(count=count_false_positive))\n",
    "print(\"false negative: {count}\".format(count=count_false_negative))\n",
    "\n",
    "print(\"precision: {precision}\".format(precision=count_true_positive / (count_true_positive + count_false_positive)))\n",
    "print(\"recall: {recall}\".format(recall=count_true_positive / (count_true_positive + count_false_negative)))\n",
    "print(\"accuracy: {accuracy}\".format(accuracy=(count_true_positive + count_true_negative) / len(test_df)))\n",
    "\n",
    "print(w_hat)\n",
    "for item in w_hat[0]:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cubam Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [[len(df), prompt_num, len(df) * prompt_num]]\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    for prompt_id in range(prompt_num):\n",
    "        output.append([i, prompt_id, row[\"{key}_prompt{num}\".format(key=key, num=prompt_id)]])\n",
    "    i += 1\n",
    "with open(\"label.txt\", 'w') as f:\n",
    "    for line in output:\n",
    "        f.write(\" \".join([str(i) for i in line]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.4446456096171754, 0.21379937526649273] 0.48083095985264906 2.248982062053791\n",
      "1 [3.172758533777183, -0.5641261344362055] -0.17780304691659307 0.3151831409021523\n",
      "2 [3.436186205080825, -1.1998247219100042] -0.34917337137781285 0.29102031738599515\n",
      "3 [2.7086938679319257, -0.8375718435492641] -0.3092161330836349 0.369181623600564\n",
      "4 [0.29179406410424463, 0.21817924256140594] 0.7477165213458917 3.4270745125327355\n",
      "5 [3.959005306353944, -1.0554132712806252] -0.2665854651891363 0.2525886990843547\n",
      "6 [2.674907186779974, -0.6516298888518697] -0.24360841081603848 0.37384474681672597\n",
      "7 [1.5049356146651278, 1.7496457403099246] 1.1626050465283517 0.6644802543413234\n",
      "8 [2.6871688966755047, 0.4051346015291729] 0.1507663333072941 0.37213887122509265\n",
      "9 [0.44800648165338014, 0.5286294900685734] 1.1799594687060149 2.2321105630201434\n",
      "0.48083095985264906\n",
      "-0.17780304691659307\n",
      "-0.34917337137781285\n",
      "-0.3092161330836349\n",
      "0.7477165213458917\n",
      "-0.2665854651891363\n",
      "-0.24360841081603848\n",
      "1.1626050465283517\n",
      "0.1507663333072941\n",
      "1.1799594687060149\n",
      "----\n",
      "2.248982062053791\n",
      "0.3151831409021523\n",
      "0.29102031738599515\n",
      "0.369181623600564\n",
      "3.4270745125327355\n",
      "0.2525886990843547\n",
      "0.37384474681672597\n",
      "0.6644802543413234\n",
      "0.37213887122509265\n",
      "2.2321105630201434\n",
      "score\n",
      "0 1.3701\n",
      "1 6.1677\n",
      "2 6.5232\n",
      "3 5.1082\n",
      "4 1.3313\n",
      "5 7.6514\n",
      "6 5.1062\n",
      "7 4.1725\n",
      "8 5.5251\n",
      "9 2.076\n",
      "[0.9616872969311369, 0.5300151856026531, -0.0793456634110587, -0.17852261968140945, -1.2761099388515134, -0.36269924832015854, -0.12938738525721016, -1.2761099388515134, -0.40912319310495265, -0.5599832427501024, -1.2761099388515134, 0.1860656802752567, -1.2761099388515134, -0.09387087946022607, -1.2761099388515134, 0.5300151856026531, -0.36414538493118725, -0.010916094126215838, -1.2761099388515134, -0.03478120101902769, -0.23285458338998974, -0.25339569153148983, -0.44639667051967163, -0.39798361203889493, -0.8876584325836114, 0.027286482475203593, 0.34047904910405735, -0.34349580596959733, -0.9341169442039531, -0.44639667051967163, 0.8308307884111162, -0.8307323692889185, -0.2640030134401748, -0.17852261968140945, -1.2761099388515134, -0.19605323150813717, -0.4096521304474619, -0.8307323692889185, -0.492535050245675, -1.0951531473688794, 0.17159081191803532, 0.19173584208744918, -0.5373056490426479, -0.2219665559978436, 1.2566505009819795, -0.4096521304474619, -0.0793456634110587, -0.5676249710044067, -0.23263536110860586, -0.620570310669993, 0.5300151856026531, -0.5131843851341839, 0.6597761803776127, -0.007330400889786064, -0.32351987385837133, -0.05326833902724026, -1.2761099388515134, -1.2761099388515134, -0.5902152659206097, -0.035807142387955085, -0.19605323150813717, -1.0254321891673148, -0.3183662543651033, -0.4096521304474619, -0.9341169442039531, -0.21949199642051942, -0.37800239292090093, 0.06815374692940053, -1.0951531473688794, -0.8876584325836114, -1.2761099388515134, 0.5300151856026531, -0.8307323692889185, 0.5300151856026531, -0.598930513042855, 0.005151594073948069, -0.620570310669993, -0.42271763207848206, -1.2761099388515134, -0.620570310669993, 0.9616872969311369, 0.5300151856026531, -0.925630886444535, -0.18689415232938997, 0.08177697293450893, -1.0951531473688794, -1.2761099388515134, -0.8876584325836114, -0.12938738525721016, -1.2761099388515134, 0.1860656802752567, -0.5673515997024405, 0.14505937110230868, -1.2761099388515134, -0.8307323692889185, -1.0254321891673148, -0.5330138825463794, -0.12148510644078955, 0.08177697293450893, -0.3852144219652671, -1.2761099388515134, -0.587641204969601, -0.18389475872975417, -0.44639667051967163, -1.2761099388515134, -0.8307323692889185, 0.5300151856026531, 0.4359464263588682, -0.8876584325836114, -1.0254321891673148, -1.2761099388515134, -1.0254321891673148, -0.026486674271193687, -0.3086929041859823, -0.8876584325836114, -1.0951531473688794, 1.338368521784704, -0.10972092163883228, -0.05972965364602027, -1.2761099388515134, -1.2761099388515134, -0.5599832427501024, -0.4504017899242406, -0.18215603907456393, -0.48979852524039, -0.5389621637504549, -0.21949199642051942, -0.23480004855542433, -0.5131843851341839, -1.0951531473688794, -0.18158821603245295, -1.2761099388515134, 0.6597761803776127, -0.2888285014074778, 0.9616872969311369, -0.10879502091735654, -0.5549663588321887, 0.018091536901777405, -1.0254321891673148, -0.5655159618021705, -0.38642114591777443, -0.02787338007922326, -0.8307323692889185, -0.603832383832443, 0.2645417553142835, -0.09271899838947911, 0.14505937110230868, 0.10083984368992477, 0.20951195322335725, -1.2761099388515134, -0.05451300236400816, 0.11206915236965662, -0.5676249710044067, -0.21949199642051942, -1.2761099388515134, -1.2761099388515134, -0.3639041560946143, 0.6618542693566092, -0.5358945200820546, -0.598930513042855, -0.3560290559280876, -0.3781449182864532, -0.5922079375098946, -0.21686080513018582, -1.2761099388515134, -1.2761099388515134, -1.0951531473688794, -0.0091342746193447, -0.4977569567066093, 0.009338164261043213, -0.386569239464346, -0.036838101697023694, -1.2761099388515134, -0.8307323692889185, -0.24206671848633865, 0.5300151856026531, -0.8307323692889185, 0.163513608753917, -1.2761099388515134, -0.19067971790588664, -0.8876584325836114, -0.5676249710044067, -1.2761099388515134, 0.5300151856026531, -0.10972092163883228, -0.20060047168548686, -0.12921785625691914, -0.5389621637504549, -0.9341169442039531, -1.2761099388515134, -0.5676249710044067, 0.24887518377725334, -1.2761099388515134, -0.33801467017204145, -1.2761099388515134, -0.5676249710044067, -0.10879502091735654, -1.2761099388515134, -1.2761099388515134, -0.34857688436342826, -0.492535050245675, 0.2510218255983568, -1.0951531473688794, -0.19605323150813717, 1.338368521784704, -1.2761099388515134, 0.005151594073948069, -1.2761099388515134, -1.2761099388515134, -0.6261402515462611, -0.9341169442039531, -1.2761099388515134, -0.8307323692889185, -1.2761099388515134, 0.009338164261043213, -0.9341169442039531, -0.3544931333818451, -0.5676249710044067, 0.9616872969311369, -0.620570310669993, -0.620570310669993, -0.21686080513018582, -1.2761099388515134, -1.2761099388515134, -0.20073106775083374, 0.9616872969311369, 0.07223145474692037, -1.2761099388515134, -0.03478120101902769, 1.7485613374574835, -1.0951531473688794, 0.14505937110230868, 0.09392271074156586, -0.19605323150813717, 1.4940834373588714, -1.0254321891673148, -1.2761099388515134, -1.2761099388515134, 0.5300151856026531, 1.7485613374574835, -0.3481055685981696, -0.5922079375098946, 0.2151099127942698, -0.13798928464011742, -1.2761099388515134, -1.0951531473688794, -0.603832383832443, -1.0254321891673148, -0.4977569567066093, -0.8307323692889185, -1.2761099388515134, -0.17961638101571284, -0.8307323692889185, 0.17159081191803532, -0.9341169442039531, 0.7660668774850597, -1.2761099388515134, -1.0254321891673148, -1.0951531473688794, -0.19454749193324034, 0.34047904910405735, -0.6261402515462611, -0.027542784885045885, -1.2761099388515134, -0.2566866361958347, 0.1860656802752567, -0.3481055685981696, -1.0951531473688794, -0.2888285014074778, -0.06312584315522966, 0.19173584208744918, -1.2761099388515134, -0.603832383832443, 1.1135597473417587, -0.5131843851341839, -0.27788059171612894, -0.40912319310495265, -1.2761099388515134, -0.027542784885045885, -0.925630886444535, -0.34857688436342826, 0.5300151856026531, -1.0951531473688794, -0.3893604736133379, -0.25690794020540775, -1.2761099388515134, -0.5676249710044067, -0.25339569153148983, -0.4076077008301371, -0.9341169442039531, -1.0951531473688794, 0.2645417553142835, -0.5332045584010687, -0.23480004855542433, -1.2761099388515134, 0.17159081191803532, 0.14505937110230868, -0.18689415232938997, -1.2761099388515134, -0.603832383832443, -0.10647412130988686, -0.925630886444535, -0.17478915421572624, 0.08177697293450893, -1.2761099388515134, -0.2025935428148616, 1.5796980817483781, -1.2761099388515134, 0.14505937110230868, 0.5300151856026531, -0.21949199642051942, -0.569461861028898, -0.9341169442039531, -0.12938738525721016, 0.5300151856026531, 1.7485613374574835, -0.2556413595120938, 0.14505937110230868, -1.2761099388515134, -1.0951531473688794, 0.2151099127942698, -1.0254321891673148, -0.5390758347919334, 0.7678070837263112, -0.5131843851341839, 0.7660668774850597, -0.5922079375098946, -1.0254321891673148, -1.2761099388515134, -0.03648280106261617, -0.550088663438973, -0.29779652073371177, -0.05451300236400816, -0.0754798078518872, -0.33801467017204145, 0.14505937110230868, 0.9616872969311369, -0.40912319310495265, 0.5300151856026531, -0.18215603907456393, 0.15082507273080334, -0.4096521304474619, -0.24206671848633865, -0.12162439823223443, -0.16070902508335394, 0.2324567726737132, 0.9616872969311369, -0.5390758347919334, -0.2888285014074778, 0.5300151856026531, -0.5373056490426479, -0.05347198101736445, 0.7660668774850597, -1.2761099388515134, -1.2761099388515134, -0.5599832427501024, -0.8307323692889185, 1.1135597473417587, 0.028552219596340363, 0.6110087822691025, -0.0793456634110587, -1.2761099388515134, -1.2761099388515134, -0.17478915421572624, -0.6261402515462611, -0.620570310669993, -0.8876584325836114, -0.5330138825463794, 0.13538141718672494, -0.5131843851341839, 0.6597761803776127, -1.2761099388515134, -0.23263536110860586, -1.2761099388515134, 0.9616872969311369, -0.550088663438973, -0.20548806385615237, 0.5300151856026531, 1.4898793020404502, 0.005151594073948069, -0.598930513042855, 0.11711881553772097, -0.8307323692889185, -0.8307323692889185, -1.0254321891673148, -1.0951531473688794, 0.044023338902434414, -0.2556413595120938, 0.5300151856026531, -0.4977569567066093, -0.8307323692889185, -0.27788059171612894, -1.2761099388515134, -0.25035482367475526, -0.603832383832443, -0.15744259031504962, -1.0951531473688794, -0.44639667051967163, -1.2761099388515134, -0.5488479257048818]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from cubam.Binary1dSignalModel import Binary1dSignalModel\n",
    "model = Binary1dSignalModel()\n",
    "model.load_data(\"label.txt\")\n",
    "model.optimize_param()\n",
    "eprm = {\n",
    "    'wkr' : model.get_worker_param(), \n",
    "    'img' : model.get_image_param()\n",
    "}\n",
    "score = []\n",
    "w = 2\n",
    "for index in range(len(eprm['wkr'])):\n",
    "    print(index, eprm['wkr'][index], eprm['wkr'][index][1] / eprm['wkr'][index][0], 1 / eprm['wkr'][index][0])\n",
    "    score.append(round(8 - abs(8 - eprm['wkr'][index][1] / eprm['wkr'][index][0]) + w * eprm['wkr'][index][0], 4))\n",
    "    \n",
    "for index in range(len(eprm['wkr'])):\n",
    "    print(eprm['wkr'][index][1] / eprm['wkr'][index][0])\n",
    "print(\"----\")\n",
    "for index in range(len(eprm['wkr'])):\n",
    "    print(1 / eprm['wkr'][index][0])\n",
    "print(\"score\")\n",
    "for index in range(len(score)):\n",
    "    print(index, score[index])\n",
    "getParameter = lambda prmdict, pidx: [prmdict[i][pidx] for i \\\n",
    "                                          in range(len(prmdict))]\n",
    "exi = getParameter(model.get_image_param(), 0)\n",
    "print(exi)\n",
    "estimated_result_binary_biased = [1 if item > 0 else 0 for item in exi]\n",
    "print(estimated_result_binary_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.36363636 0.65656566] 1.805555555334028 2.7499999997937503\n",
      "1 [0.78787879 0.84848485] 1.0769230769133136 1.2692307693235207\n",
      "2 [0.91919192 0.77777778] 0.8461538461705833 1.0879120880113151\n",
      "3 [0.87878788 0.78787879] 0.8965517241497027 1.1379310345808562\n",
      "4 [0.38383838 0.63636364] 1.6578947366707062 2.60526315773705\n",
      "5 [0.86868687 0.82828283] 0.9534883720983776 1.1511627907953894\n",
      "6 [0.84848485 0.82828283] 0.9761904761932824 1.1785714286682398\n",
      "7 [0.06060606 0.95959596] 15.833333308858334 16.499999976075003\n",
      "8 [0.5959596  0.96969697] 1.627118643962568 1.6779661017489516\n",
      "9 [0.26262626 0.75757576] 2.8846153838977813 3.8076923070039945\n",
      "score\n",
      "0 2.5328\n",
      "1 2.6527\n",
      "2 2.6845\n",
      "3 2.6541\n",
      "4 2.4256\n",
      "5 2.6909\n",
      "6 2.6732\n",
      "7 -11.7121\n",
      "8 2.819\n",
      "9 1.6406\n",
      "[0.9999338450748534, 0.9999123117222124, 0.9207285896071209, 0.22945303084376734, 1.2569089959732664e-05, 0.016120586212857498, 0.8833287105238407, 1.2569089959732664e-05, 0.01333676945419096, 0.00026137202380279047, 1.2569089959732664e-05, 0.9962252969109889, 1.2569089959732664e-05, 0.9001665000656568, 1.2569089959732664e-05, 0.9999123117222124, 0.011219762526714163, 0.9390089674805738, 1.2569089959732664e-05, 0.9074142516853413, 0.2344190494342564, 0.2189260906921136, 0.009059890987670932, 0.007616532034327997, 1.528268129717187e-05, 0.9974449922748356, 0.9973058728839832, 0.0126993144392951, 1.496893813572309e-05, 0.009059890987670932, 0.9999278807166982, 1.6660605013754736e-05, 0.284084992096548, 0.22945303084376734, 1.2569089959732664e-05, 0.2493242377781747, 0.01329623981761024, 1.6660605013754736e-05, 0.0006628716969723261, 1.3702353033806914e-05, 0.996217456257136, 0.9982215928812518, 0.000556656688418648, 0.19721380807780517, 0.9999475031676004, 0.01329623981761024, 0.9207285896071209, 0.0005001628949282247, 0.18344001084889325, 0.00033940233459033264, 0.9999123117222124, 0.00040091764582753325, 0.9999197309039831, 0.9420197449125329, 0.017144888433129606, 0.8994355196398915, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.00037658198352102067, 0.9611706712023081, 0.2493242377781747, 1.3730922657930176e-05, 0.009837558037604712, 0.01329623981761024, 1.496893813572309e-05, 0.301345247692349, 0.010301371403270688, 0.9970769278208246, 1.3702353033806914e-05, 1.528268129717187e-05, 1.2569089959732664e-05, 0.9999123117222124, 1.6660605013754736e-05, 0.9999123117222124, 0.000369992861957182, 0.9972094741487544, 0.00033940233459033264, 0.009889078106781019, 1.2569089959732664e-05, 0.00033940233459033264, 0.9999338450748534, 0.9999123117222124, 1.525088301274453e-05, 0.4032452327993779, 0.9981792450691428, 1.3702353033806914e-05, 1.2569089959732664e-05, 1.528268129717187e-05, 0.8833287105238407, 1.2569089959732664e-05, 0.9962252969109889, 0.0004041800594312365, 0.9958778130990482, 1.2569089959732664e-05, 1.6660605013754736e-05, 1.3730922657930176e-05, 0.000646341895174861, 0.9297240572212156, 0.9981792450691428, 0.014821667322537256, 1.2569089959732664e-05, 0.0003707640275283591, 0.451560466306826, 0.009059890987670932, 1.2569089959732664e-05, 1.6660605013754736e-05, 0.9999123117222124, 0.9977368282758379, 1.528268129717187e-05, 1.3730922657930176e-05, 1.2569089959732664e-05, 1.3730922657930176e-05, 0.9087145517006374, 0.019006717729075334, 1.528268129717187e-05, 1.3702353033806914e-05, 0.9999476123923615, 0.8585209965619612, 0.8997141859483562, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.00026137202380279047, 0.0005313579788371598, 0.265828453940783, 0.00034642630487667305, 0.0005463711791496336, 0.301345247692349, 0.18390251010174546, 0.00040091764582753325, 1.3702353033806914e-05, 0.22999886422296478, 1.2569089959732664e-05, 0.9999197309039831, 0.1597829359682356, 0.9999338450748534, 0.9542256933076839, 0.000412648151042722, 0.9222113339316527, 1.3730922657930176e-05, 0.0004117899050482675, 0.014551640658536561, 0.9663960874793421, 1.6660605013754736e-05, 0.00036885374476276203, 0.9968870019782617, 0.9415272470680691, 0.9958778130990482, 0.9983295822766669, 0.9982161084614776, 1.2569089959732664e-05, 0.9269461559173698, 0.9983638192319763, 0.0005001628949282247, 0.301345247692349, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.000530716641085668, 0.9999212147535483, 0.0004498373952241138, 0.000369992861957182, 0.01187828090751433, 0.010685065822018456, 0.00036962253698234824, 0.30069621659288154, 1.2569089959732664e-05, 1.2569089959732664e-05, 1.3702353033806914e-05, 0.9156274697787842, 0.0004370501595220013, 0.9224323308018005, 0.014507473386179385, 0.9337446769647919, 1.2569089959732664e-05, 1.6660605013754736e-05, 0.2345988815554807, 0.9999123117222124, 1.6660605013754736e-05, 0.9986257776074438, 1.2569089959732664e-05, 0.45104468729957153, 1.528268129717187e-05, 0.0005001628949282247, 1.2569089959732664e-05, 0.9999123117222124, 0.8585209965619612, 0.2788681809551173, 0.9493147705695487, 0.0005463711791496336, 1.496893813572309e-05, 1.2569089959732664e-05, 0.0005001628949282247, 0.9984611644850523, 1.2569089959732664e-05, 0.009012651490789114, 1.2569089959732664e-05, 0.0005001628949282247, 0.9542256933076839, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.01760183530401983, 0.0006628716969723261, 0.9989114668698859, 1.3702353033806914e-05, 0.2493242377781747, 0.9999476123923615, 1.2569089959732664e-05, 0.9972094741487544, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.00033835736624163545, 1.496893813572309e-05, 1.2569089959732664e-05, 1.6660605013754736e-05, 1.2569089959732664e-05, 0.9224323308018005, 1.496893813572309e-05, 0.009245717316848567, 0.0005001628949282247, 0.9999338450748534, 0.00033940233459033264, 0.00033940233459033264, 0.30069621659288154, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.2714970249105806, 0.9999338450748534, 0.9319927522783927, 1.2569089959732664e-05, 0.9074142516853413, 0.9999568242145255, 1.3702353033806914e-05, 0.9958778130990482, 0.9973729523538597, 0.2493242377781747, 0.9999519449938017, 1.3730922657930176e-05, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.9999123117222124, 0.9999568242145255, 0.017548574916437056, 0.00036962253698234824, 0.9965364090889566, 0.3056768077119551, 1.2569089959732664e-05, 1.3702353033806914e-05, 0.00036885374476276203, 1.3730922657930176e-05, 0.0004370501595220013, 1.6660605013754736e-05, 1.2569089959732664e-05, 0.34285765938955337, 1.6660605013754736e-05, 0.996217456257136, 1.496893813572309e-05, 0.9999263692125767, 1.2569089959732664e-05, 1.3730922657930176e-05, 1.3702353033806914e-05, 0.21506751551067513, 0.9973058728839832, 0.00033835736624163545, 0.9071547737358004, 1.2569089959732664e-05, 0.28450879890127667, 0.9962252969109889, 0.017548574916437056, 1.3702353033806914e-05, 0.1597829359682356, 0.9268049845011828, 0.9982215928812518, 1.2569089959732664e-05, 0.00036885374476276203, 0.9999427701175349, 0.00040091764582753325, 0.26685930061384255, 0.01333676945419096, 1.2569089959732664e-05, 0.9071547737358004, 1.525088301274453e-05, 0.01760183530401983, 0.9999123117222124, 1.3702353033806914e-05, 0.007774932837677041, 0.38876779544956824, 1.2569089959732664e-05, 0.0005001628949282247, 0.2189260906921136, 0.010771112361397652, 1.496893813572309e-05, 1.3702353033806914e-05, 0.9968870019782617, 0.00028552556454880534, 0.18390251010174546, 1.2569089959732664e-05, 0.996217456257136, 0.9958778130990482, 0.4032452327993779, 1.2569089959732664e-05, 0.00036885374476276203, 0.39717684791916485, 1.525088301274453e-05, 0.26623515350234445, 0.9981792450691428, 1.2569089959732664e-05, 0.3191552481511947, 0.9999529314990689, 1.2569089959732664e-05, 0.9958778130990482, 0.9999123117222124, 0.301345247692349, 0.0004105221578654081, 1.496893813572309e-05, 0.8833287105238407, 0.9999123117222124, 0.9999568242145255, 0.22585024865462766, 0.9958778130990482, 1.2569089959732664e-05, 1.3702353033806914e-05, 0.9965364090889566, 1.3730922657930176e-05, 0.0004484525665925504, 0.9999277303556474, 0.00040091764582753325, 0.9999263692125767, 0.00036962253698234824, 1.3730922657930176e-05, 1.2569089959732664e-05, 0.9069791948692573, 0.0005929167421738256, 0.010937177134658806, 0.9269461559173698, 0.9530421684228064, 0.009012651490789114, 0.9958778130990482, 0.9999338450748534, 0.01333676945419096, 0.9999123117222124, 0.265828453940783, 0.9978762238091772, 0.01329623981761024, 0.2345988815554807, 0.9503036082515317, 0.2834361322248596, 0.9966072740996401, 0.9999338450748534, 0.0004484525665925504, 0.1597829359682356, 0.9999123117222124, 0.000556656688418648, 0.9281997595561362, 0.9999263692125767, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.00026137202380279047, 1.6660605013754736e-05, 0.9999427701175349, 0.9965207517236694, 0.9999195635528048, 0.9207285896071209, 1.2569089959732664e-05, 1.2569089959732664e-05, 0.26623515350234445, 0.00033835736624163545, 0.00033940233459033264, 1.528268129717187e-05, 0.000646341895174861, 0.9978429572898403, 0.00040091764582753325, 0.9999197309039831, 1.2569089959732664e-05, 0.18344001084889325, 1.2569089959732664e-05, 0.9999338450748534, 0.0005929167421738256, 0.31982589981609655, 0.9999123117222124, 0.9999528333637769, 0.9972094741487544, 0.000369992861957182, 0.9976367752181653, 1.6660605013754736e-05, 1.6660605013754736e-05, 1.3730922657930176e-05, 1.3702353033806914e-05, 0.9968075904604519, 0.22585024865462766, 0.9999123117222124, 0.0004370501595220013, 1.6660605013754736e-05, 0.26685930061384255, 1.2569089959732664e-05, 0.2663322505043787, 0.00036885374476276203, 0.36304451431341633, 1.3702353033806914e-05, 0.009059890987670932, 1.2569089959732664e-05, 0.0005452349611056298]\n",
      "[1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from cubam.BinaryBiasModel import BinaryBiasModel\n",
    "model = BinaryBiasModel()\n",
    "model.load_data(\"label.txt\")\n",
    "model.optimize_param()\n",
    "eprm = {\n",
    "    'wkr' : model.get_worker_param(), \n",
    "    'img' : model.get_image_param()\n",
    "}\n",
    "score = []\n",
    "w = 2\n",
    "for index in range(len(eprm['wkr'])):\n",
    "    print(index, eprm['wkr'][index], eprm['wkr'][index][1] / eprm['wkr'][index][0], 1 / eprm['wkr'][index][0])\n",
    "    score.append(round(2 - abs(2 - eprm['wkr'][index][1] / eprm['wkr'][index][0]) + w * eprm['wkr'][index][0], 4))\n",
    "print(\"score\")\n",
    "for index in range(len(score)):\n",
    "    print(index, score[index])\n",
    "getParameter = lambda prmdict, pidx: [prmdict[i][pidx] for i \\\n",
    "                                          in range(len(prmdict))]\n",
    "exi = getParameter(model.get_image_param(), 0)\n",
    "print(exi)\n",
    "estimated_result_binary_biased = [1 if item > 0.5 else 0 for item in exi]\n",
    "print(estimated_result_binary_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive: 50\n",
      "true negative: 237\n",
      "false positive: 77\n",
      "false negative: 36\n",
      "precision: 0.3937007874015748\n",
      "recall: 0.5813953488372093\n",
      "accuracy: 0.7175\n"
     ]
    }
   ],
   "source": [
    "df[\"estimate_result\"] = estimated_result_binary_biased\n",
    "\n",
    "count_true_positive = len(df[(df['estimate_result'] == 1) & (df['label'] == golden_label)])\n",
    "count_true_negative = len(df[(df['estimate_result'] == 0) & (df['label'] != golden_label)])\n",
    "count_false_positive = len(df[(df['estimate_result'] == 1) & (df['label'] != golden_label)])\n",
    "count_false_negative = len(df[(df['estimate_result'] == 0) & (df['label'] == golden_label)])\n",
    "print(\"true positive: {count}\".format(count=count_true_positive))\n",
    "print(\"true negative: {count}\".format(count=count_true_negative))\n",
    "print(\"false positive: {count}\".format(count=count_false_positive))\n",
    "print(\"false negative: {count}\".format(count=count_false_negative))\n",
    "\n",
    "print(\"precision: {precision}\".format(precision=count_true_positive / (count_true_positive + count_false_positive)))\n",
    "print(\"recall: {recall}\".format(recall=count_true_positive / (count_true_positive + count_false_negative)))\n",
    "print(\"accuracy: {accuracy}\".format(accuracy=(count_true_positive + count_true_negative) / len(df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
