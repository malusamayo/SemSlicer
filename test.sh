#!/bin/sh
CUDA_LAUNCH_BLOCKING=1 python llama.py